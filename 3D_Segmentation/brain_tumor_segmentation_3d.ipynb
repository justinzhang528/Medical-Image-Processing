{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License.\n",
    "\n",
    "# Brain tumor 3D segmentation with MONAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selab1623/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    "    Spacingd,\n",
    "    Resized,\n",
    "    RandRotated,\n",
    "    RandZoomd,\n",
    "    RandAffined,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import logging\n",
    "from importlib import reload\n",
    "\n",
    "# print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/PETCT/\n"
     ]
    }
   ],
   "source": [
    "root_dir = './data/PETCT/'\n",
    "roi_size = (128,128,64)\n",
    "print(root_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#leave-one-out cross validation data for pet-ct big tumor & normal patients\n",
    "ours_images = sorted(glob.glob(root_dir+\"train/ours/*petct.nii.gz\"))\n",
    "ours_labels = sorted(glob.glob(root_dir+\"train/ours/*seg.nii.gz\"))\n",
    "ours_images_normal = sorted(glob.glob('./data/normal_petct/*petct.nii.gz'))\n",
    "ours_labels_normal = sorted(glob.glob('./data/normal_petct/*mask.nii.gz'))\n",
    "ours_data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(ours_images, ours_labels)]\n",
    "ours_data_dicts_normal = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(ours_images_normal, ours_labels_normal)]\n",
    "ours_data_dicts += ours_data_dicts_normal\n",
    "loocv_files_set = []\n",
    "for i in range(len(ours_data_dicts)):\n",
    "    train_test_files = ours_data_dicts[:i]+ours_data_dicts[i+1:]\n",
    "    test_files = [ours_data_dicts[i]]\n",
    "    loocv_files_set.append([train_test_files, test_files])\n",
    "fold_num = 1\n",
    "loocv_test_files = loocv_files_set[fold_num-1][1]\n",
    "print(len(train_test_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a new transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 4 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            # merge labels 1, 2 and 4 to construct whole tumor\n",
    "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 4), d[key] == 1))\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d\n",
    "\n",
    "\n",
    "class NormalizeFrom0to1(MapTransform):\n",
    "  def __call__(self, data):\n",
    "      d = dict(data)\n",
    "      for key in self.keys:\n",
    "          d[key] = (d[key] - torch.min(d[key])) / (torch.max(d[key]) - torch.min(d[key]))\n",
    "      return d\n",
    "\n",
    "\n",
    "class AdjustLabelValued(MapTransform):\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            d[key][d[key]<0.5] = 0\n",
    "            d[key][d[key]>=0.5] = 1\n",
    "        return d\n",
    "\n",
    "import cv2        \n",
    "def gradient(img):\n",
    "    gradient_x = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "    gradient_y = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "    gradient_x = np.absolute(gradient_x)\n",
    "    gradient_y = np.absolute(gradient_y)\n",
    "\n",
    "    # 合併x和y方向的梯度\n",
    "    gradient_combined = cv2.addWeighted(gradient_x, 0.5, gradient_y, 0.5, 0)\n",
    "    return torch.Tensor(gradient_combined)\n",
    "    \n",
    "class Derivateived(MapTransform):\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            batch_size = d[key].shape[0]\n",
    "            depth = d[key].shape[3]\n",
    "            for i in range(batch_size):\n",
    "                for j in range(depth):\n",
    "                    d[key][i,:,:,j] = gradient(np.asarray(d[key][i,:,:,j]))\n",
    "        return d\n",
    "    \n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),        \n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        Derivateived(keys=\"image\"),\n",
    "        AdjustLabelValued(keys=\"label\"),\n",
    "        NormalizeFrom0to1(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "affine_transforms = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),\n",
    "        RandAffined(keys=[\"image\", \"label\"],prob=1.0,shear_range=(0.4,0.4),translate_range=(0.1,0.3)),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        AdjustLabelValued(keys=\"label\"),\n",
    "        NormalizeFrom0to1(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rot_transforms = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),\n",
    "        RandRotated(keys=[\"image\", \"label\"],range_z=[0.2,0.5],prob=1.0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        AdjustLabelValued(keys=\"label\"),\n",
    "        NormalizeFrom0to1(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "zoom_transforms = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),\n",
    "        RandZoomd(keys=[\"image\", \"label\"],prob=1.0, min_zoom=0.6, max_zoom=0.9),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        AdjustLabelValued(keys=\"label\"),\n",
    "        NormalizeFrom0to1(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rot_zoom_transforms = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),\n",
    "        RandZoomd(keys=[\"image\", \"label\"],prob=1.0, min_zoom=0.6, max_zoom=0.9),\n",
    "        RandRotated(keys=[\"image\", \"label\"],range_z=[-0.2,-0.5],prob=1.0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        AdjustLabelValued(keys=\"label\"),\n",
    "        NormalizeFrom0to1(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),\n",
    "        AdjustLabelValued(keys=\"label\"),\n",
    "        NormalizeFrom0to1(keys=\"image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=loocv_files_set[0][0], transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "print(check_data[\"image\"].shape)\n",
    "print(check_data[\"label\"].shape)\n",
    "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "print(np.unique(image))\n",
    "print(np.unique(label))\n",
    "cols = 2\n",
    "rows = image.shape[2]\n",
    "fig = plt.figure(\"check\", (4, 100))\n",
    "for i in range(rows):\n",
    "    fig.add_subplot(rows,cols,(i*cols)+1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(image[:, :, i], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(rows,cols,(i*cols)+2)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(label[:, :, i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CacheDataset and DataLoader for training and validation\n",
    "\n",
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.  \n",
    "To achieve best performance, set `cache_rate=1.0` to cache all the data, if memory is not enough, set lower value.  \n",
    "Users can also set `cache_num` instead of `cache_rate`, will use the minimum value of the 2 settings.  \n",
    "And set `num_workers` to enable multi-threads during caching.  \n",
    "If want to to try the regular Dataset, just change to use the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0)\n",
    "val_loader = DataLoader(val_ds, batch_size=1)\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weights were loaded, all weights being used are randomly initialized!\n"
     ]
    }
   ],
   "source": [
    "use_pretrained = False\n",
    "pretrained_path = './SSL/models/01/best_model.pt'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=(16, 32, 64, 128, 256),\n",
    "#     strides=(2, 2, 2, 2),\n",
    "#     num_res_units=2,\n",
    "#     norm=Norm.BATCH,\n",
    "# ).to(device)\n",
    "\n",
    "model = SwinUNETR(\n",
    "    img_size=roi_size,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    feature_size=48,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    use_checkpoint=True,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./brats2021_flair_240_240_64/models/swinunetr/transfer learning/swinunetr-best_metric_model.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute a typical PyTorch training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "#reload logger\n",
    "logging.shutdown()\n",
    "reload(logging)\n",
    "logging.basicConfig(filename=root_dir+'training_log.txt',filemode='a',format='%(message)s',level=logging.DEBUG)\n",
    "\n",
    "for epoch in range(max_epochs,200):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_loader) // train_loader.batch_size}\" f\"-> train_loss: {loss.item():.4f}\",end='| ')\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print('\\n',f\"epoch {epoch + 1} => average loss: {epoch_loss:.4f}\",end='| ')\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = roi_size\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            print(\n",
    "                f\"mean dice: {metric:.4f}\\n\"\n",
    "            )\n",
    "            \n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "\n",
    "            logging.info(f'Epoch {epoch + 1} - average loss: {epoch_loss:.4f} | mean dice: {metric:.4f}| best mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}')\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(root_dir, \"last_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, best_metric: 0.0006 at epoch: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")\n",
    "torch.save(model.state_dict(), os.path.join(root_dir, \"last_model.pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (24, 6))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_org_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),\n",
    "        AdjustLabelValued(keys=\"label\"),\n",
    "        NormalizeFrom0to1(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_images = sorted(glob.glob('./data/normal_flair/*mri.nii.gz'))\n",
    "test_labels = sorted(glob.glob('./data/normal_flair/*mask.nii.gz'))\n",
    "test_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(test_images, test_labels)]\n",
    "test_org_ds = Dataset(data=test_files, transform=test_org_transforms)\n",
    "test_org_loader = DataLoader(test_org_ds, batch_size=1)\n",
    "check_data = first(test_org_loader)\n",
    "print(check_data[\"image\"].shape)\n",
    "print(len(test_org_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show prediction result images and save as png\n",
    "model.load_state_dict(torch.load(os.path.join('./data/brats2021_flair_240_240_64/last_model.pth')))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_files)):\n",
    "        test_file = [test_files[i]]\n",
    "        test_org_ds = Dataset(data=test_file, transform=test_org_transforms)\n",
    "        test_org_loader = DataLoader(test_org_ds, batch_size=1)\n",
    "        for c, test_data in enumerate(test_org_loader):\n",
    "            shape = test_data[\"image\"].shape\n",
    "            labelShape = test_data[\"label\"].shape\n",
    "            roi_size = roi_size\n",
    "            sw_batch_size = 1\n",
    "            test_outputs = sliding_window_inference(test_data[\"image\"].to(device), roi_size, sw_batch_size, model)\n",
    "            cols = 3\n",
    "            rows = test_data[\"image\"].shape[4]\n",
    "            fig = plt.figure(\"check\", (12, 200))\n",
    "            for j in range(rows):\n",
    "                fig.add_subplot(rows,cols,(j*cols)+1)\n",
    "                plt.title(\"image\")\n",
    "                plt.imshow(test_data[\"image\"][0, 0, :, :, j], cmap=\"gray\")\n",
    "                plt.axis('off')\n",
    "                fig.add_subplot(rows,cols,(j*cols)+2)\n",
    "                plt.title(\"ground truth\")\n",
    "                plt.imshow(test_data[\"label\"][0, 0, :, :, j])\n",
    "                plt.axis('off')\n",
    "                fig.add_subplot(rows,cols,(j*cols)+3)\n",
    "                plt.title(\"predict\")\n",
    "                plt.imshow(torch.argmax(test_outputs, dim=1).detach().cpu()[0, :, :, j])\n",
    "                plt.axis('off')\n",
    "            fig.savefig(root_dir+test_file[0][\"image\"].split('/')[-1][:-11]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print prediction result\n",
    "print('id, meandice')\n",
    "total_dice = 0\n",
    "for i in range(len(test_files)):\n",
    "    test_file = [test_files[i]]\n",
    "    test_org_ds = Dataset(data=test_file, transform=test_org_transforms)\n",
    "    test_org_loader = DataLoader(test_org_ds, batch_size=1)\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(root_dir, \"last_model.pth\")))\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_org_loader:\n",
    "            roi_size = roi_size\n",
    "            sw_batch_size = 1\n",
    "            test_data[\"pred\"] = sliding_window_inference(test_data[\"image\"].to(device), roi_size, sw_batch_size, model).detach().cpu()\n",
    "            test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
    "            test_outputs, test_labels = from_engine([\"pred\", \"label\"])(test_data)\n",
    "            # compute metric for current iteration\n",
    "            dice_metric(y_pred=test_outputs, y=test_labels)\n",
    "\n",
    "        # aggregate the final mean dice result\n",
    "        metric_org = dice_metric.aggregate().item()\n",
    "        # reset the status for next validation round\n",
    "        dice_metric.reset()\n",
    "\n",
    "    print(test_file[0][\"image\"].split('/')[-1][:-11], end=(', '))\n",
    "    print(f\"{metric_org:.4f}\", end=(', '))\n",
    "    total_dice += metric_org\n",
    "print(f\"meandice: {(total_dice/len(test_files)):.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leave-one-out-cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave one out cross validation\n",
    "loocv_result = []\n",
    "max_epochs = 100\n",
    "for c,v in enumerate(loocv_files_set):\n",
    "    train_files = v[0]\n",
    "    loocv_test_files = v[1]\n",
    "\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0)\n",
    "\n",
    "    # Data augmentation\n",
    "    for i in range(4):\n",
    "        affine_ds = CacheDataset(data=train_files, transform=affine_transforms, cache_rate=1.0)\n",
    "        rot_ds = CacheDataset(data=train_files, transform=rot_transforms, cache_rate=1.0)\n",
    "        zoom_ds = CacheDataset(data=train_files, transform=zoom_transforms, cache_rate=1.0)\n",
    "        rot_zoom_ds = CacheDataset(data=train_files, transform=rot_zoom_transforms, cache_rate=1.0)\n",
    "        train_ds += affine_ds+rot_ds+zoom_ds+rot_zoom_ds\n",
    "    \n",
    "    train_size = int(len(train_ds)*0.8)\n",
    "    val_size = len(train_ds)-train_size\n",
    "    train_ds, val_ds = data.random_split(train_ds,[train_size,val_size])\n",
    "    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1)\n",
    "    print(len(train_loader))\n",
    "    print(len(val_loader))\n",
    "\n",
    "\n",
    "    use_pretrained = True\n",
    "    pretrained_path = './SSL/models/MRI/SwinVit-Triplet Loss+L1 Loss/epoch_300_model.pt'\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SwinUNETR(\n",
    "        img_size=roi_size,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        feature_size=48,\n",
    "        drop_rate=0.0,\n",
    "        attn_drop_rate=0.0,\n",
    "        dropout_path_rate=0.0,\n",
    "        use_checkpoint=True,\n",
    "    ).to(device)\n",
    "\n",
    "    if use_pretrained is True:\n",
    "        \n",
    "        # Load swinvit backbone weights into SwinUNETR\n",
    "        print(\"Loading Weights from the Path {}\".format(pretrained_path))\n",
    "        model_dict = torch.load(pretrained_path)\n",
    "        state_dict = model_dict[\"state_dict\"]\n",
    "        model_weights = {k: v for k, v in state_dict.items()}\n",
    "\n",
    "        # fix potential differences in state dict keys from pre-training to\n",
    "        # fine-tuning\n",
    "        if \"module.\" in list(state_dict.keys())[0]:\n",
    "            print(\"Tag 'module.' found in state dict - fixing!\")\n",
    "            for key in list(state_dict.keys()):\n",
    "                state_dict[key.replace(\"module.\", \"\")] = state_dict.pop(key)\n",
    "        if \"swin_vit\" in list(state_dict.keys())[0]:\n",
    "            print(\"Tag 'swin_vit' found in state dict - fixing!\")\n",
    "            for key in list(state_dict.keys()):\n",
    "                state_dict[key.replace(\"swin_vit\", \"swinViT\")] = state_dict.pop(key)\n",
    "        # We now load model weights, setting param `strict` to False, i.e.:\n",
    "        # this load the encoder weights (Swin-ViT, SSL pre-trained), but leaves\n",
    "        # the decoder weights untouched (CNN UNet decoder).\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        for name, para in model.named_parameters():\n",
    "            flag = name in model_weights\n",
    "            print(flag)\n",
    "            if flag:\n",
    "                para.requires_grad = False\n",
    "        print(\"Using pretrained self-supervised Swin UNETR backbone weights !\")\n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "    elif use_pretrained is False:\n",
    "        print(\"No weights were loaded, all weights being used are randomly initialized!\")\n",
    "\n",
    "    loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "    # loss_function = FocalLoss(to_onehot_y=True, gamma=2.0, use_softmax=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "\n",
    "    val_interval = 1\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "    post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "    #reload logger\n",
    "    logging.shutdown()\n",
    "    reload(logging)\n",
    "    logging.basicConfig(filename=root_dir+'training_log.txt',filemode='a',format='%(message)s',level=logging.DEBUG)\n",
    "    logging.info('loocv-Fold-'+str(c+1).zfill(3)+':')\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = (\n",
    "                batch_data[\"image\"].to(device),\n",
    "                batch_data[\"label\"].to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(f\"{step}/{len(train_loader) // train_loader.batch_size}\" f\"-> train_loss: {loss.item():.4f}\",end='| ')\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print('\\n',f\"epoch {epoch + 1} => average loss: {epoch_loss:.4f}\",end='| ')\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_inputs, val_labels = (\n",
    "                        val_data[\"image\"].to(device),\n",
    "                        val_data[\"label\"].to(device),\n",
    "                    )\n",
    "                    roi_size = roi_size\n",
    "                    sw_batch_size = 4\n",
    "                    val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                    val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                    val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                    # compute metric for current iteration\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                # aggregate the final mean dice result\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                # reset the status for next validation round\n",
    "                dice_metric.reset()\n",
    "\n",
    "                metric_values.append(metric)\n",
    "                print(\n",
    "                    f\"mean dice: {metric:.4f}\\n\"\n",
    "                )\n",
    "\n",
    "                logging.info(f'Epoch {epoch + 1} - average loss: {epoch_loss:.4f} | mean dice: {metric:.4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(root_dir, \"fold\"+str(c).zfill(3)+\"_last_model.pth\"))\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------- #\n",
    "    # Prediction:\n",
    "    test_org_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            Spacingd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                pixdim=(1.0, 1.0, 1.0),\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "            ),\n",
    "            Resized(keys=[\"image\", \"label\"],spatial_size=roi_size),\n",
    "            AdjustLabelValued(keys=\"label\"),\n",
    "            NormalizeFrom0to1(keys=\"image\"),        \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    post_transforms = Compose(\n",
    "        [\n",
    "            AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_file = loocv_test_files\n",
    "    total_dice = 0\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(root_dir, \"fold\"+str(c).zfill(3)+\"_last_model.pth\")))\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_file)):\n",
    "            test_file = [test_file[i]]\n",
    "            test_org_ds = Dataset(data=test_file, transform=test_org_transforms)\n",
    "            test_org_loader = DataLoader(test_org_ds, batch_size=1)\n",
    "            for count, test_data in enumerate(test_org_loader):\n",
    "                shape = test_data[\"image\"].shape\n",
    "                labelShape = test_data[\"label\"].shape\n",
    "                roi_size = roi_size\n",
    "                sw_batch_size = 1\n",
    "                test_outputs = sliding_window_inference(test_data[\"image\"].to(device), roi_size, sw_batch_size, model)\n",
    "                cols = 3\n",
    "                rows = test_data[\"image\"].shape[4]\n",
    "                fig = plt.figure(\"check\", (12, 200))\n",
    "                for j in range(rows):\n",
    "                    fig.add_subplot(rows,cols,(j*cols)+1)\n",
    "                    plt.title(\"image\")\n",
    "                    plt.imshow(test_data[\"image\"][0, 0, :, :, j], cmap=\"gray\")\n",
    "                    plt.axis('off')\n",
    "                    fig.add_subplot(rows,cols,(j*cols)+2)\n",
    "                    plt.title(\"ground truth\")\n",
    "                    plt.imshow(test_data[\"label\"][0, 0, :, :, j])\n",
    "                    plt.axis('off')\n",
    "                    fig.add_subplot(rows,cols,(j*cols)+3)\n",
    "                    plt.title(\"predict\")\n",
    "                    plt.imshow(torch.argmax(test_outputs, dim=1).detach().cpu()[0, :, :, j])\n",
    "                    plt.axis('off')\n",
    "                fig.savefig(root_dir+test_file[0][\"image\"].split('\\\\')[-1][:-11]+'.png')\n",
    "\n",
    "                test_data[\"pred\"] = test_outputs.detach().cpu()\n",
    "                test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
    "                test_outputs, test_labels = from_engine([\"pred\", \"label\"])(test_data)\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=test_outputs, y=test_labels)\n",
    "            \n",
    "            # aggregate the final mean dice result \n",
    "            metric_org = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "        patient_id = test_file[0][\"image\"].split('\\\\')[-1][:-11]\n",
    "        print(patient_id, end=(', '))\n",
    "        print(f\"{metric_org:.4f}\", end=(', '))\n",
    "        total_dice += metric_org\n",
    "    average_dice = total_dice/len(test_file)\n",
    "    loocv_result.append(f\"{patient_id},{(average_dice):.4f}\")\n",
    "    print(f\"meandice: {(average_dice):.4f}\")\n",
    "    logging.info(patient_id)\n",
    "    logging.info(f\"meandice: {(average_dice):.4f}\")\n",
    "\n",
    "for s in loocv_result:\n",
    "    logging.info(s)\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "700f5e5557bcb25000d0ae9567e955defef2b0a59e783294a554959233bb6a64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceab8707",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b68c35c3",
   "metadata": {},
   "source": [
    "# Self-Supervised Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "707541a2",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49070e05",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf64bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import L1Loss\n",
    "from torch.nn import TripletMarginLoss\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    CopyItemsd,\n",
    "    SpatialPadd,\n",
    "    EnsureChannelFirstd,\n",
    "    Spacingd,\n",
    "    OneOf,\n",
    "    RandCoarseDropoutd,\n",
    "    RandCoarseShuffled,\n",
    "    MapTransform,\n",
    ")\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from importlib import reload\n",
    "from ssl_head import SSLHead\n",
    "from tripletLoss import TripletLoss\n",
    "\n",
    "# print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72e2e12c",
   "metadata": {},
   "source": [
    "##### Define file paths & output directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "657217e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../brats2021_flair_240_240_64/'\n",
    "logdir_path = './log/'\n",
    "roi_size = (128,128,64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7adf9d64",
   "metadata": {},
   "source": [
    "##### Create result logging directories, manage data paths & set determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f084405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240+240+120\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(logdir_path) is False:\n",
    "    os.mkdir(logdir_path)\n",
    "    \n",
    "top_images = sorted(glob.glob(root_dir+\"train/top/*mri.nii.gz\"))\n",
    "bottom_images = sorted(glob.glob(root_dir+\"train/bottom/*mri.nii.gz\"))\n",
    "# train_labels = sorted(glob.glob(root_dir+\"train/*seg.nii.gz\"))\n",
    "\n",
    "# data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "data_dicts_top = [{\"image\": image_name} for image_name in zip(top_images)]\n",
    "data_dicts_bottom = [{\"image\": image_name} for image_name in zip(bottom_images)]\n",
    "\n",
    "train_files_top, val_files_top = data_dicts_top[:240], data_dicts_top[240:300]\n",
    "train_files_bottom, val_files_bottom = data_dicts_bottom[:240], data_dicts_bottom[240:300]\n",
    "val_files = val_files_top + val_files_bottom\n",
    "print(len(train_files_top),end='+')\n",
    "print(len(train_files_bottom),end='+')\n",
    "print(len(val_files))\n",
    "\n",
    "# Set Determinism\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d106d4ea",
   "metadata": {},
   "source": [
    "##### Define MONAI Transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ebbdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justin\\Desktop\\monai\\MONAI\\monai\\utils\\deprecate_utils.py:321: FutureWarning: monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "class NormalizeFrom0to1(MapTransform):\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            d[key] = (d[key] - torch.min(d[key])) / (torch.max(d[key]) - torch.min(d[key]))\n",
    "        return d\n",
    "    \n",
    "# Define Training Transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(2.0, 2.0, 1.0), mode=(\"bilinear\")),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        SpatialPadd(keys=[\"image\"], spatial_size=roi_size),\n",
    "        NormalizeFrom0to1(keys=[\"image\"]),\n",
    "        CopyItemsd(keys=[\"image\"], times=2, names=[\"gt_image\", \"image_2\"], allow_missing_keys=False),\n",
    "        OneOf(\n",
    "            transforms=[\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image\"], prob=1.0, holes=6, spatial_size=5, dropout_holes=True, max_spatial_size=20\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        RandCoarseShuffled(keys=[\"image\"], prob=0.8, holes=10, spatial_size=8),\n",
    "        # Please note that that if image, image_2 are called via the same transform call because of the determinism\n",
    "        # they will get augmented the exact same way which is not the required case here, hence two calls are made\n",
    "        OneOf(\n",
    "            transforms=[\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image_2\"], prob=1.0, holes=6, spatial_size=20, dropout_holes=False, max_spatial_size=64\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        RandCoarseShuffled(keys=[\"image_2\"], prob=0.8, holes=10, spatial_size=8),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_files_bottom, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "print(check_data[\"image\"].shape)\n",
    "image = (check_data[\"image\"][0][0])\n",
    "print(f\"image shape: {image.shape}\")\n",
    "print(np.unique(image))\n",
    "cols = 2\n",
    "rows = image.shape[2]\n",
    "fig = plt.figure(\"check\", (4, 100))\n",
    "for i in range(rows):\n",
    "    fig.add_subplot(rows,cols,(i*cols)+1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(image[:, :, i], cmap=\"gray\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e3453c4",
   "metadata": {},
   "source": [
    "##### Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 240/240 [00:50<00:00,  4.74it/s]\n",
      "Loading dataset: 100%|██████████| 240/240 [00:53<00:00,  4.47it/s]\n",
      "Loading dataset: 100%|██████████| 120/120 [00:26<00:00,  4.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training Config\n",
    "\n",
    "# Define Network ViT backbone & Loss & Optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "# model = ViTAutoEnc(\n",
    "#     in_channels=1,\n",
    "#     img_size=roi_size,\n",
    "#     patch_size=(16, 16, 16),\n",
    "#     pos_embed=\"conv\",\n",
    "#     hidden_size=768,\n",
    "#     mlp_dim=3072,\n",
    "# )\n",
    "model = SSLHead()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Hyper-paramters for training loop\n",
    "max_epochs = 500\n",
    "val_interval = 2\n",
    "batch_size = 1\n",
    "lr = 1e-4\n",
    "epoch_loss_values = []\n",
    "epoch_tri_loss_values = []\n",
    "epoch_recon_loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = 1000.0\n",
    "\n",
    "recon_loss = L1Loss()\n",
    "triplet_loss = TripletMarginLoss(margin=1.0, p=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Define DataLoader using MONAI, CacheDataset needs to be used\n",
    "train_ds_top = CacheDataset(data=train_files_top, transform=train_transforms, cache_rate=1.0)\n",
    "train_loader_top = DataLoader(train_ds_top, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_ds_bottom = CacheDataset(data=train_files_bottom, transform=train_transforms, cache_rate=1.0)\n",
    "train_loader_bottom = DataLoader(train_ds_bottom, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=train_transforms, cache_rate=1.0)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8b292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join('./log/best_model.pt')))\n",
    "swinvit_dict = torch.load('./models/MRI/SwinVit-Triplet Loss+L1 Loss/best_model.pt')\n",
    "swinvit_weights = swinvit_dict[\"state_dict\"]\n",
    "model.load_state_dict(swinvit_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60b1912d",
   "metadata": {},
   "source": [
    "##### Training loop with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d71ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload logger\n",
    "logging.shutdown()\n",
    "reload(logging)\n",
    "logging.basicConfig(filename=logdir_path+'training_log.txt',filemode='a',format='%(message)s',level=logging.DEBUG)\n",
    "\n",
    "for epoch in range(109,max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_tri_loss = 0\n",
    "    epoch_recon_loss = 0\n",
    "    step = 0    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_ds_size = len(train_ds_top) + len(train_ds_bottom)\n",
    "\n",
    "    for (batch_data_top, batch_data_bottom) in zip(train_loader_top, train_loader_bottom):\n",
    "        step += 1\n",
    "\n",
    "        anchor_input, positive_input, gt_input = (\n",
    "            batch_data_top[\"image\"].to(device),\n",
    "            batch_data_top[\"image_2\"].to(device),\n",
    "            batch_data_top[\"gt_image\"].to(device),\n",
    "        )\n",
    "        negative_input = batch_data_bottom[\"image\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        anchor = model(anchor_input)\n",
    "        positive = model(positive_input)\n",
    "        negative = model(negative_input)\n",
    "\n",
    "        r_loss = recon_loss(anchor, gt_input)\n",
    "        tri_loss = triplet_loss(anchor, positive, negative)\n",
    "\n",
    "        total_loss = r_loss + tri_loss * r_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "\n",
    "        epoch_tri_loss += tri_loss.item()\n",
    "        epoch_recon_loss += r_loss.item()\n",
    "\n",
    "        print(\n",
    "            f\"{step}/{train_ds_size // train_loader_top.batch_size}, \"\n",
    "            f\"train_loss: {total_loss.item():.4f}\"\n",
    "            f\" | tri_loss: {tri_loss.item():.4f}\"\n",
    "            f\" | recon_loss: {r_loss.item():.4f}\"\n",
    "        )\n",
    "\n",
    "    for (batch_data_top, batch_data_bottom) in zip(train_loader_top, train_loader_bottom):\n",
    "        step += 1\n",
    "\n",
    "        anchor_input, positive_input, gt_input = (\n",
    "            batch_data_bottom[\"image\"].to(device),\n",
    "            batch_data_bottom[\"image_2\"].to(device),\n",
    "            batch_data_bottom[\"gt_image\"].to(device),\n",
    "        )\n",
    "        negative_input = batch_data_top[\"image\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        anchor = model(anchor_input)\n",
    "        positive = model(positive_input)\n",
    "        negative = model(negative_input)\n",
    "\n",
    "        r_loss = recon_loss(anchor, gt_input)\n",
    "        tri_loss = triplet_loss(anchor, positive, negative)\n",
    "\n",
    "        total_loss = r_loss + tri_loss * r_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "\n",
    "        epoch_tri_loss += tri_loss.item()\n",
    "        epoch_recon_loss += r_loss.item()\n",
    "\n",
    "        print(\n",
    "            f\"{step}/{train_ds_size // train_loader_top.batch_size}, \"\n",
    "            f\"train_loss: {total_loss.item():.4f}\"\n",
    "            f\" | tri_loss: {tri_loss.item():.4f}\"\n",
    "            f\" | recon_loss: {r_loss.item():.4f}\"\n",
    "        )\n",
    "    \n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_tri_loss /= step\n",
    "    epoch_recon_loss /= step\n",
    "\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    epoch_tri_loss_values.append(epoch_tri_loss)\n",
    "    epoch_recon_loss_values.append(epoch_recon_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    logging.info(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if epoch % val_interval == 0:\n",
    "        print(\"Entering Validation for epoch: {}\".format(epoch + 1))\n",
    "        total_val_loss = 0\n",
    "        val_step = 0\n",
    "        model.eval()\n",
    "        for val_batch in val_loader:\n",
    "            val_step += 1\n",
    "            inputs, gt_input = (\n",
    "                val_batch[\"image\"].to(device),\n",
    "                val_batch[\"gt_image\"].to(device),\n",
    "            )\n",
    "            print(\"Input shape: {}\".format(inputs.shape))\n",
    "            outputs = model(inputs)\n",
    "            val_loss = recon_loss(outputs, gt_input)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        total_val_loss /= val_step\n",
    "        val_loss_values.append(total_val_loss)\n",
    "        print(f\"epoch {epoch + 1} Validation avg loss: {total_val_loss:.4f}\")\n",
    "\n",
    "        if total_val_loss < best_val_loss:\n",
    "            print(f\"Saving new model based on validation loss {total_val_loss:.4f}\")\n",
    "            logging.info(f\"Saving new model based on validation loss {total_val_loss:.4f}\")\n",
    "            best_val_loss = total_val_loss\n",
    "            checkpoint = {\"epoch\": max_epochs, \"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "            torch.save(checkpoint, os.path.join(logdir_path, \"best_model.pt\"))\n",
    "        \n",
    "        if epoch%100==0:\n",
    "            checkpoint = {\"epoch\": max_epochs, \"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "            torch.save(checkpoint, os.path.join(logdir_path, f\"epoch_{epoch}_model.pt\"))\n",
    "\n",
    "        plt.figure(1, figsize=(8, 8))\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(epoch_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Training Loss\")\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(val_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Validation Loss\")\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(epoch_tri_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Training Triplet Loss\")\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(epoch_recon_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Training Recon Loss\")\n",
    "\n",
    "        plt.savefig(os.path.join(logdir_path, \"loss_plots.png\"))\n",
    "        plt.close(1)    \n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"time taken: {end_time-start_time}s\")\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "da3e08083059755bb70e9f8b58ba677201225f59652efa5b6b39528ae9381865"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

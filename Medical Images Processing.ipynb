{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9369be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "c:\\ProgramData\\Anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pydicom import dcmread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.util import montage\n",
    "from skimage import io\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "tf.__version__\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "\n",
    "import math\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d143419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw dicom images with metadata info\n",
    "from datetime import datetime\n",
    "def drawCategorizedImages(folderPath, dict, fontsize=10, fontfamily='MingLiU'):\n",
    "    for patient in dict:\n",
    "        for study in dict[patient]:\n",
    "            for series in dict[patient][study]:\n",
    "                fileList = dict[patient][study][series]\n",
    "                imagesList = []\n",
    "                for file in fileList:\n",
    "                    imagesList.append(dcmread(folderPath + file['dcmPath']))\n",
    "                imagesList.sort(key=lambda x: x.InstanceNumber, reverse=False) # sort image by instance number\n",
    "                quantity = len(imagesList)\n",
    "                cols = 10\n",
    "                rows = math.ceil(quantity/cols)\n",
    "                rows = rows + int(rows/6) + 1 # add blank rows to place text\n",
    "                fig = plt.figure(figsize=(cols*2,rows*2))\n",
    "                flag = True\n",
    "                for i in range(quantity):\n",
    "                    ds = imagesList[i]\n",
    "\n",
    "                    if (\"PixelData\" in ds):\n",
    "                        #add text only once\n",
    "                        if flag:\n",
    "                            plt.text(0.01,0.14,\"PatientName: \" + str(ds.PatientName), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.01,0.11,\"PatientID: \" + str(ds.PatientID), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.01,0.08,\"Sex: \" + str(ds.PatientSex), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.33,0.14,\"InstitutionName: \" + ds.InstitutionName if ds.InstitutionName != \"\" else \"InstitutionName: None\", fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.33,0.11,\"StudyDescription: \" + ds.StudyDescription, fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.33,0.08,\"StudyID: \" + ds.StudyID, fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.14,\"SeriesNumber: \" + str(ds.SeriesNumber), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.11,\"SeriesDescription: \" + str(ds.SeriesDescription), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.08,\"AccessionNumber: \" + ds.AccessionNumber, fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.05,\"AcquisitionDate: \" + str(datetime.strptime(ds.AcquisitionDate, '%Y%m%d').date()), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.02,\"AcquisitionTime: \" + ds.AcquisitionTime, fontsize=fontsize, fontfamily=fontfamily)\n",
    "#                             plt.text(0.66,0.085,\"SliceThickness: \" + str(math.ceil(ds.SliceThickness)) + \"mm\", fontsize=fontsize, fontfamily=fontfamily)\n",
    "#                             plt.text(0.66,0.06,\"SliceLocation: \" + str(math.ceil(ds.SliceLocation)) + \"mm\", fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            flag = False   \n",
    "\n",
    "                        fig.add_subplot(rows, cols, i+1)\n",
    "                        if(len(ds.pixel_array.shape)==3):\n",
    "                            plt.imshow(ds.pixel_array[:,:,1])\n",
    "                        else:\n",
    "                            plt.imshow(ds.pixel_array)\n",
    "                        plt.axis('off')\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def showImagesWithPyPlot(images,cmap):\n",
    "    quantity = len(images)\n",
    "    cols = 9\n",
    "    rows = math.ceil(quantity/cols)\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=(22,2.5*rows))\n",
    "    for i in range(quantity):\n",
    "        ax[i//cols][i%cols].imshow(images[i],cmap=cmap)\n",
    "        ax[i//cols][i%cols].axis('off')\n",
    "\n",
    "def showNiftiImagesWithPyPlot(nifti,cmap):\n",
    "    quantity = nifti.shape[2]\n",
    "    cols = 9\n",
    "    rows = math.ceil(quantity/cols)\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=(22,2.5*rows))\n",
    "    for i in range(quantity):\n",
    "        ax[i//cols][i%cols].imshow(nifti[:,:,i],cmap=cmap)\n",
    "        ax[i//cols][i%cols].axis('off')\n",
    "\n",
    "##################################################################\n",
    "\n",
    "#使用json檔案畫實心標記區域\n",
    "def fillMissingPoint(segments):\n",
    "    startX = segments[0]['a'][0]\n",
    "    startY = segments[0]['a'][1]\n",
    "    endX = segments[len(segments)-1]['b'][0]\n",
    "    endY = segments[len(segments)-1]['b'][1]\n",
    "    width = segments[0]['width']\n",
    "    distanceX = abs(endX-startX)\n",
    "    distanceY = abs(endY-startY)    \n",
    "    stepX = 1\n",
    "    if(distanceX<=distanceY):\n",
    "        stepX = distanceX/distanceY\n",
    "    stepY = 1\n",
    "    if(distanceY<=distanceX):\n",
    "        stepY = distanceY/distanceX\n",
    "    if(endX >= startX and endY >= startY):\n",
    "        while(endX >= startX and endY >= startY):\n",
    "            a = [endX,endY]\n",
    "            endX-=stepX\n",
    "            endY-=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    elif(endX >= startX and endY <= startY):\n",
    "        while(endX >= startX and endY <= startY):\n",
    "            a = [endX,endY]\n",
    "            endX-=stepX\n",
    "            endY+=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    elif(endX <= startX and endY <= startY):\n",
    "        while(endX <= startX and endY <= startY):\n",
    "            a = [endX,endY]\n",
    "            endX+=stepX\n",
    "            endY+=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    elif(endX <= startX and endY >= startY):\n",
    "        while(endX <= startX and endY >= startY):\n",
    "            a = [endX,endY]\n",
    "            endX+=stepX\n",
    "            endY-=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    return segments\n",
    "\n",
    "def getLabeledImageWithJson(jsonPath):\n",
    "    file = open(jsonPath)\n",
    "    data = json.load(file)\n",
    "    image = Image.new(\"RGB\", data['size'])\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    shapes = data['shapes']\n",
    "    for shape in shapes:\n",
    "        segments = shape['segments']\n",
    "        segments = fillMissingPoint(segments)\n",
    "        strokeColor = shape['strokeColor']\n",
    "        for segment in segments:\n",
    "            startEndCoord = [(segment['a'][0], segment['a'][1]),(segment['b'][0], segment['b'][1])]\n",
    "            draw.line(startEndCoord, fill=strokeColor)\n",
    "    \n",
    "    # 找輪廓並填充顔色\n",
    "    grayImage  = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(grayImage, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        cv2.drawContours(grayImage,[c], 0, (255,255,255), -1)\n",
    "\n",
    "    colorImage = cv2.cvtColor(grayImage,cv2.COLOR_GRAY2RGB)\n",
    "    colorImage[np.all(colorImage == (255, 255, 255), axis=-1)] = ImageColor.getcolor(strokeColor, \"RGB\")    \n",
    "    \n",
    "    #convert black background to transparent\n",
    "    _, alpha = cv2.threshold(grayImage, 0, 255, cv2.THRESH_BINARY)\n",
    "    b, g, r = cv2.split(colorImage)\n",
    "    rgba = [b, g, r, alpha]\n",
    "    colorImage = cv2.merge(rgba, 4)\n",
    "    \n",
    "    #convert cv2 to pil format\n",
    "    pilImage = Image.fromarray(colorImage)\n",
    "    return pilImage\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# categorize dicom files with patientID, studyID and seriesID without using dicomdir\n",
    "# 查找自己的json標記檔是否存在，如果不存在label設爲no，否則label設爲json標記檔的路徑\n",
    "def getLabelPath(dcmPath, sopInstanceUID):\n",
    "    jsonFiles = glob.glob(dcmPath.split('\\\\')[0] + \"/*.json\")\n",
    "    for jsonFile in jsonFiles:\n",
    "        if(sopInstanceUID in jsonFile):\n",
    "            return jsonFile\n",
    "    return 'NA'\n",
    "\n",
    "# dict: {patientID->studyID->seriesID->{dcmPath,labelPath}}\n",
    "def getCategorizedDictByFolder(path):\n",
    "    files = glob.glob(path + \"*.dcm\")\n",
    "    dict = {}\n",
    "    for file in files:\n",
    "        ds = dcmread(file)\n",
    "        patientID = ds.PatientID\n",
    "        studyID = ds.StudyID\n",
    "        seriesID = str(ds.SeriesNumber)\n",
    "        labelPath = getLabelPath(file, ds.SOPInstanceUID)\n",
    "        data = {'dcmPath':file,'labelPath':labelPath}\n",
    "        if patientID in dict:\n",
    "            if studyID in dict[patientID]:\n",
    "                if seriesID in dict[patientID][studyID]:\n",
    "                    dict[patientID][studyID][seriesID].append(data)\n",
    "                else:\n",
    "                    dict[patientID][studyID][seriesID] = [data]\n",
    "            else:\n",
    "                dict[patientID][studyID] = {seriesID:[data]}\n",
    "        else:\n",
    "            dict[patientID] = {studyID:{seriesID:[data]}}\n",
    "\n",
    "    # sort dict by InstanceNumber\n",
    "    for patient in dict:\n",
    "            for study in dict[patient]:\n",
    "                for series in dict[patient][study]:\n",
    "                    dict[patient][study][series].sort(key=lambda x: dcmread(x['dcmPath']).InstanceNumber, reverse=False)\n",
    "\n",
    "    return dict\n",
    "\n",
    "def getSeriesIDByName(dict, name):\n",
    "    for patient in dict:\n",
    "        for study in dict[patient]:\n",
    "            for series in dict[patient][study]:\n",
    "                for i in dict[patient][study][series]:\n",
    "                    if(name.lower() in dcmread(i['dcmPath']).SeriesDescription.lower()):\n",
    "                        return series\n",
    "##################################################################\n",
    "\n",
    "# 調整圖像色階\n",
    "def adjust_color_scale(img,Shadow,Highlight):\n",
    "    if Highlight > 255:\n",
    "        Highlight = 255\n",
    "    if Shadow < 0:\n",
    "        Shadow = 0\n",
    "    if Shadow >= Highlight:\n",
    "        Shadow = Highlight - 2\n",
    "    # 转类型\n",
    "    img = np.array(img, dtype=int)\n",
    "    # 计算白场黑场离差\n",
    "    Diff = Highlight - Shadow\n",
    "    # 计算系数\n",
    "    coe = 255.0 / Diff\n",
    "    rgbDiff = img - Shadow\n",
    "    rgbDiff = np.maximum(rgbDiff, 0)\n",
    "    img = rgbDiff * coe\n",
    "    # 四舍五入到整数\n",
    "    img = np.around(img, 0)\n",
    "    # 变为int型\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 計算兩張圖片的相似度（https://www.twblogs.net/a/5ee8804f38b2869e41a03399）\n",
    "\n",
    "# 均值哈希算法\n",
    "def aHash(img):\n",
    "    # 縮放爲8*8\n",
    "    img = cv2.resize(img, (8, 8))\n",
    "    # 轉換爲灰度圖\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # s爲像素和初值爲0，hash_str爲hash值初值爲''\n",
    "    s = 0\n",
    "    hash_str = ''\n",
    "    # 遍歷累加求像素和\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            s = s + gray[i, j]\n",
    "    # 求平均灰度\n",
    "    avg = s / 64\n",
    "    # 灰度大於平均值爲1相反爲0生成圖片的hash值\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if gray[i, j] > avg:\n",
    "                hash_str = hash_str + '1'\n",
    "            else:\n",
    "                hash_str = hash_str + '0'\n",
    "    return hash_str\n",
    "# 差值感知算法\n",
    "def dHash(img):\n",
    "    img = cv2.resize(img, (9, 8))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    hash_str = ''\n",
    "    # 每行前一個像素大於後一個像素爲1，相反爲0，生成哈希\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if gray[i, j] > gray[i, j + 1]:\n",
    "                hash_str = hash_str + '1'\n",
    "            else:\n",
    "                hash_str = hash_str + '0'\n",
    "    return hash_str\n",
    "# 感知哈希算法(pHash)\n",
    "def pHash(img):\n",
    "    img = cv2.resize(img, (32, 32))  # , interpolation=cv2.INTER_CUBIC\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 將灰度圖轉爲浮點型，再進行dct變換\n",
    "    dct = cv2.dct(np.float32(gray))\n",
    "    # opencv實現的掩碼操作\n",
    "    dct_roi = dct[0:8, 0:8]\n",
    "\n",
    "    hash = []\n",
    "    avreage = np.mean(dct_roi)\n",
    "    for i in range(dct_roi.shape[0]):\n",
    "        for j in range(dct_roi.shape[1]):\n",
    "            if dct_roi[i, j] > avreage:\n",
    "                hash.append(1)\n",
    "            else:\n",
    "                hash.append(0)\n",
    "    return hash\n",
    "# Hash值對比\n",
    "def cmpHash(hash1, hash2):\n",
    "    n = 0\n",
    "    # hash長度不同則返回-1代表傳參出錯\n",
    "    if len(hash1)!=len(hash2):\n",
    "        return -1\n",
    "    # 遍歷判斷\n",
    "    for i in range(len(hash1)):\n",
    "        # 不相等則n計數+1，n最終爲相似度\n",
    "        if hash1[i] != hash2[i]:\n",
    "            n = n + 1\n",
    "    return n\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# interpolating between two images\n",
    "import matplotlib.cm as cm\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "def inter(images,t):\n",
    "    # input: \n",
    "    # images: list of arrays/frames ordered according to motion\n",
    "    # t: parameter ranging from 0 to 1 corresponding to first and last frame \n",
    "    # returns: interpolated image\n",
    "\n",
    "    #direction of movement, assumed to be approx. linear \n",
    "    a=np.array(center_of_mass(images[0]))\n",
    "    b=np.array(center_of_mass(images[-1]))\n",
    "\n",
    "    #find index of two nearest frames\n",
    "    arr=np.array([center_of_mass(images[i]) for i in range(len(images))])\n",
    "    v=a+t*(b-a) #convert t into vector \n",
    "    idx1 = (np.linalg.norm((arr - v),axis=1)).argmin()\n",
    "    arr[idx1]=np.array([0,0]) #this is sloppy, should be changed if relevant values are near [0,0]\n",
    "    idx2 = (np.linalg.norm((arr - v),axis=1)).argmin()\n",
    "\n",
    "    if idx1>idx2:\n",
    "        b=np.array(center_of_mass(images[idx1])) #center of mass of nearest contour\n",
    "        a=np.array(center_of_mass(images[idx2])) #center of mass of second nearest contour\n",
    "        tstar=np.linalg.norm(v-a)/np.linalg.norm(b-a) #define parameter ranging from 0 to 1 for interpolation between two nearest frames\n",
    "        im1_shift=shift(images[idx2],(b-a)*tstar) #shift frame 1\n",
    "        im2_shift=shift(images[idx1],-(b-a)*(1-tstar)) #shift frame 2\n",
    "        return im1_shift+im2_shift #return average\n",
    "\n",
    "    if idx1<idx2:\n",
    "        b=np.array(center_of_mass(images[idx2]))\n",
    "        a=np.array(center_of_mass(images[idx1]))\n",
    "        tstar=np.linalg.norm(v-a)/np.linalg.norm(b-a)\n",
    "        im1_shift=shift(images[idx2],-(b-a)*(1-tstar))\n",
    "        im2_shift=shift(images[idx1],(b-a)*(tstar))\n",
    "        return im1_shift+im2_shift\n",
    "\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# convert dicom's pixel array to image looks like what we see on standard DICOM viewers\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut, apply_modality_lut\n",
    "\n",
    "def get_LUT_value_LINEAR_EXACT(data, window, level):\n",
    "    \"\"\"\n",
    "    Adjust according to VOI LUT, window center(level) and width values\n",
    "    not normalized\n",
    "    \"\"\"\n",
    "    data_min = data.min()\n",
    "    data_max = data.max()\n",
    "    data_range = data_max - data_min\n",
    "    data = np.piecewise(data, \n",
    "        [data<=(level-(window)/2),\n",
    "        data>(level+(window)/2)],\n",
    "        [data_min, data_max, lambda data: ((data-level+window/2)/window*data_range)+data_min])\n",
    "    return data\n",
    "\n",
    "def pixel_process(ds, pixel_array):\n",
    "    \"\"\"\n",
    "    Process the images\n",
    "    input image info and original pixeal_array\n",
    "    applying LUTs: Modality LUT -> VOI LUT -> Presentation LUT    \n",
    "    return processed pixel_array, in 8bit; RGB if color\n",
    "    \"\"\"\n",
    "    \n",
    "    ## LUTs: Modality LUT -> VOI LUT -> Presentation LUT\n",
    "    # Modality LUT, Rescale slope, Rescale Intercept\n",
    "    if 'RescaleSlope' in ds and 'RescaleIntercept' in ds:\n",
    "        # try applying rescale slope/intercept\n",
    "        # cannot use INT, because rescale slope could be<1 \n",
    "        rescale_slope = float(ds.RescaleSlope) # int(ds.RescaleSlope)\n",
    "        rescale_intercept = float(ds.RescaleIntercept) #  int(ds.RescaleIntercept)\n",
    "        pixel_array = (pixel_array) * rescale_slope + rescale_intercept\n",
    "    else:\n",
    "        # otherwise, try to apply modality \n",
    "        pixel_array = apply_modality_lut(pixel_array, ds)\n",
    "\n",
    "\n",
    "    # personally prefer sigmoid function than window/level\n",
    "    # personally prefer LINEAR_EXACT than LINEAR (prone to err if small window/level, such as some MR images)\n",
    "    if 'VOILUTFunction' in ds and ds.VOILUTFunction=='SIGMOID':\n",
    "        pixel_array = apply_voi_lut(pixel_array, ds)\n",
    "    elif 'WindowCenter' in ds and 'WindowWidth' in ds:\n",
    "        window_center = ds.WindowCenter\n",
    "        window_width = ds.WindowWidth\n",
    "        # some values may be stored in an array\n",
    "        if type(window_center)==pydicom.multival.MultiValue:\n",
    "            window_center = float(window_center[0])\n",
    "        else:\n",
    "            window_center = float(window_center)\n",
    "        if type(window_width)==pydicom.multival.MultiValue:\n",
    "            window_width = float(window_width[0])\n",
    "        else:\n",
    "            window_width = float(window_width)\n",
    "        pixel_array = get_LUT_value_LINEAR_EXACT(pixel_array, window_width, window_center)\n",
    "    else:\n",
    "        # if there is no window center, window width tag, try applying VOI LUT setting\n",
    "        pixel_array = apply_voi_lut(pixel_array, ds)\n",
    "        \n",
    "    # Presentation VOI\n",
    "    # normalize to 8 bit\n",
    "    pixel_array = ((pixel_array-pixel_array.min())/(pixel_array.max()-pixel_array.min())) * 255.0\n",
    "    # if PhotometricInterpretation == \"MONOCHROME1\", then inverse; eg. xrays\n",
    "    if 'PhotometricInterpretation' in ds and ds.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        # NOT add minus directly\n",
    "        pixel_array = np.max(pixel_array) - pixel_array\n",
    "    \n",
    "    # conver float -> 8-bit\n",
    "    return pixel_array.astype('uint8')\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Image shadow and highlight correction\n",
    "def imageCorrection(\n",
    "        img,\n",
    "        shadow_amount_percent, shadow_tone_percent, shadow_radius,\n",
    "        highlight_amount_percent, highlight_tone_percent, highlight_radius,\n",
    "        color_percent\n",
    "):\n",
    "    \"\"\"\n",
    "    Image Shadow / Highlight Correction. The same function as it in Photoshop / GIMP\n",
    "    :param img: input RGB image numpy array of shape (height, width, 3)\n",
    "    :param shadow_amount_percent [0.0 ~ 1.0]: Controls (separately for the highlight and shadow values in the image) how much of a correction to make.\n",
    "    :param shadow_tone_percent [0.0 ~ 1.0]: Controls the range of tones in the shadows or highlights that are modified.\n",
    "    :param shadow_radius [>0]: Controls the size of the local neighborhood around each pixel\n",
    "    :param highlight_amount_percent [0.0 ~ 1.0]: Controls (separately for the highlight and shadow values in the image) how much of a correction to make.\n",
    "    :param highlight_tone_percent [0.0 ~ 1.0]: Controls the range of tones in the shadows or highlights that are modified.\n",
    "    :param highlight_radius [>0]: Controls the size of the local neighborhood around each pixel\n",
    "    :param color_percent [-1.0 ~ 1.0]:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    shadow_tone = shadow_tone_percent * 255\n",
    "    highlight_tone = 255 - highlight_tone_percent * 255\n",
    "\n",
    "    shadow_gain = 1 + shadow_amount_percent * 6\n",
    "    highlight_gain = 1 + highlight_amount_percent * 6\n",
    "\n",
    "    # extract RGB channel\n",
    "    height, width = img.shape[:2]\n",
    "    img = img.astype(np.float)\n",
    "    img_R, img_G, img_B = img[..., 2].reshape(-1), img[..., 1].reshape(-1), img[..., 0].reshape(-1)\n",
    "\n",
    "    # The entire correction process is carried out in YUV space,\n",
    "    # adjust highlights/shadows in Y space, and adjust colors in UV space\n",
    "    # convert to Y channel (grey intensity) and UV channel (color)\n",
    "    img_Y = .3 * img_R + .59 * img_G + .11 * img_B\n",
    "    img_U = -img_R * .168736 - img_G * .331264 + img_B * .5\n",
    "    img_V = img_R * .5 - img_G * .418688 - img_B * .081312\n",
    "\n",
    "    # extract shadow / highlight\n",
    "    shadow_map = 255 - img_Y * 255 / shadow_tone\n",
    "    shadow_map[np.where(img_Y >= shadow_tone)] = 0\n",
    "    highlight_map = 255 - (255 - img_Y) * 255 / (255 - highlight_tone)\n",
    "    highlight_map[np.where(img_Y <= highlight_tone)] = 0\n",
    "\n",
    "    # // Gaussian blur on tone map, for smoother transition\n",
    "    if shadow_amount_percent * shadow_radius > 0:\n",
    "        # shadow_map = cv2.GaussianBlur(shadow_map.reshape(height, width), ksize=(shadow_radius, shadow_radius), sigmaX=0).reshape(-1)\n",
    "        shadow_map = cv2.blur(shadow_map.reshape(height, width), ksize=(shadow_radius, shadow_radius)).reshape(-1)\n",
    "\n",
    "    if highlight_amount_percent * highlight_radius > 0:\n",
    "        # highlight_map = cv2.GaussianBlur(highlight_map.reshape(height, width), ksize=(highlight_radius, highlight_radius), sigmaX=0).reshape(-1)\n",
    "        highlight_map = cv2.blur(highlight_map.reshape(height, width), ksize=(highlight_radius, highlight_radius)).reshape(-1)\n",
    "\n",
    "    # Tone LUT\n",
    "    t = np.arange(256)\n",
    "    LUT_shadow = (1 - np.power(1 - t * (1 / 255), shadow_gain)) * 255\n",
    "    LUT_shadow = np.maximum(0, np.minimum(255, np.int_(LUT_shadow + .5)))\n",
    "    LUT_highlight = np.power(t * (1 / 255), highlight_gain) * 255\n",
    "    LUT_highlight = np.maximum(0, np.minimum(255, np.int_(LUT_highlight + .5)))\n",
    "\n",
    "    # adjust tone\n",
    "    shadow_map = shadow_map * (1 / 255)\n",
    "    highlight_map = highlight_map * (1 / 255)\n",
    "\n",
    "    iH = (1 - shadow_map) * img_Y + shadow_map * LUT_shadow[np.int_(img_Y)]\n",
    "    iH = (1 - highlight_map) * iH + highlight_map * LUT_highlight[np.int_(iH)]\n",
    "    img_Y = iH\n",
    "\n",
    "    # adjust color\n",
    "    if color_percent != 0:\n",
    "        # color LUT\n",
    "        if color_percent > 0:\n",
    "            LUT = (1 - np.sqrt(np.arange(32768)) * (1 / 128)) * color_percent + 1\n",
    "        else:\n",
    "            LUT = np.sqrt(np.arange(32768)) * (1 / 128) * color_percent + 1\n",
    "\n",
    "        # adjust color saturation adaptively according to highlights/shadows\n",
    "        color_gain = LUT[np.int_(img_U ** 2 + img_V ** 2 + .5)]\n",
    "        w = 1 - np.minimum(2 - (shadow_map + highlight_map), 1)\n",
    "        img_U = w * img_U + (1 - w) * img_U * color_gain\n",
    "        img_V = w * img_V + (1 - w) * img_V * color_gain\n",
    "\n",
    "    # re convert to RGB channel\n",
    "    output_R = np.int_(img_Y + 1.402 * img_V + .5)\n",
    "    output_G = np.int_(img_Y - .34414 * img_U - .71414 * img_V + .5)\n",
    "    output_B = np.int_(img_Y + 1.772 * img_U + .5)\n",
    "\n",
    "    output = np.row_stack([output_B, output_G, output_R]).T.reshape(height, width, 3)\n",
    "    output = np.minimum(output, 255).astype(np.uint8)\n",
    "    return output\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Rescale array\n",
    "def rescaleFrom0to255(arr):\n",
    "    min_val = arr.min()\n",
    "    max_val = arr.max()\n",
    "\n",
    "    # Rescale the array\n",
    "    arr_rescaled = (arr - min_val) * (255 - 0) / (max_val - min_val) + 0\n",
    "    return arr_rescaled.astype(np.uint8)\n",
    "\n",
    "# Rescale array\n",
    "def rescaleFrom0to1(arr):\n",
    "    min_val = arr.min()\n",
    "    max_val = arr.max()\n",
    "\n",
    "    # Rescale the array\n",
    "    arr_rescaled = (arr - min_val) * (1 - 0) / (max_val - min_val) + 0\n",
    "    return arr_rescaled\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# applu CT window\n",
    "def apply_ct_window(img, window):\n",
    "    # window = (window width, window level)\n",
    "    R = (img-window[1]+0.5*window[0])/window[0]\n",
    "    R[R<0] = 0\n",
    "    R[R>1] = 1\n",
    "    return R\n",
    "\n",
    "# enlarge image layout\n",
    "def enlargeImageLayout(input,outputSize):\n",
    "    size = input.shape\n",
    "    output = np.zeros((outputSize))\n",
    "    startX = outputSize[0]//2 - size[0]//2\n",
    "    startY = outputSize[1]//2 - size[1]//2\n",
    "    output[startX:startX+size[0],startY:startY+size[1]] = input\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#superimpose original image and label\n",
    "path = \"20221005/001/001-MR/\"\n",
    "images_path = glob.glob(path + '*_0.png')\n",
    "labels_path = glob.glob(path + '*_anno.png')\n",
    "images = []\n",
    "for i in range(len(images_path)):\n",
    "    image = Image.open(images_path[i])\n",
    "    label = Image.open(labels_path[i])\n",
    "    image.paste(label,(0,0),mask=label)\n",
    "    images.append(image)\n",
    "    \n",
    "#show superimposed images with pyplot\n",
    "showImagesWithPyPlot(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e81e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw lines with pillow and add images to list\n",
    "path = \"20221005/002/002-MR/\"\n",
    "images_path = glob.glob(path + '*_0.png')\n",
    "labels_path = glob.glob(path + '*_anno.png')\n",
    "jsonFiles = glob.glob(path + \"*.json\")\n",
    "\n",
    "labelImages = []\n",
    "for i in jsonFiles:\n",
    "    labelImages.append(getLabeledImageWithJson(i))\n",
    "\n",
    "#show filledLabels with pyplot\n",
    "print(\"Quantity: \" + str(len(labelImages)))\n",
    "showImagesWithPyPlot(labelImages)\n",
    "    \n",
    "#superimpose filledLabelImages to original mri images and show\n",
    "images=[]\n",
    "for i in range(len(labelImages)):\n",
    "    image = Image.open(images_path[i])\n",
    "    labelImage = labelImages[i]\n",
    "#     alpha = Image.new(\"L\", labelImage.size, 100)\n",
    "#     labelImage.putalpha(alpha)\n",
    "    image.paste(labelImage,(0,0),mask=labelImage)\n",
    "    images.append(image)\n",
    "showImagesWithPyPlot(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize dicom files with patientID, studyID and seriesID using dicomdir\n",
    "# dict: {patientID->studyID->seriesID->{dcmPath,label}}\n",
    "# find images file name by SeriesNumber to be drawn\n",
    "from pydicom.fileset import FileSet\n",
    "dicomdir = dcmread(\"002/dicomdir\")\n",
    "fs = FileSet(dicomdir)\n",
    "# print(fs)\n",
    "\n",
    "dict = {}\n",
    "patientIDs = fs.find_values(\"PatientID\")\n",
    "for patientID in patientIDs:\n",
    "    instances = fs.find(PatientID=patientID)\n",
    "    for ds in instances:\n",
    "        patientID = ds.PatientID\n",
    "        studyID = ds.StudyID\n",
    "        seriesID = ds.SeriesNumber\n",
    "        fileName = ds.ReferencedFileID\n",
    "        data = {'dcmPath':fileName,'labelPath':'NA'}\n",
    "        if patientID in dict:\n",
    "            if studyID in dict[patientID]:\n",
    "                if seriesID in dict[patientID][studyID]:\n",
    "                    dict[patientID][studyID][seriesID].append(data)\n",
    "                else:\n",
    "                    dict[patientID][studyID][seriesID] = [data]\n",
    "            else:\n",
    "                dict[patientID][studyID] = {seriesID:[data]}\n",
    "        else:\n",
    "            dict[patientID] = {studyID:{seriesID:[data]}}\n",
    "\n",
    "#draw images\n",
    "drawCategorizedImages('002/', dict, fontsize=15, fontfamily='DejaVu Sans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06277e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照series對MRI與PET做資料夾分類，并且畫出MRI對應的標記圖像\n",
    "patientFolder = '004'\n",
    "mri_dict = getCategorizedDictByFolder('./20221005/'+ patientFolder+ '/'+ patientFolder+ '-MR/')\n",
    "pet_dict = getCategorizedDictByFolder('./20221005/'+ patientFolder+ '/'+ patientFolder+ '-PT/')\n",
    "\n",
    "for patient in mri_dict:\n",
    "    for study in mri_dict[patient]:\n",
    "        for series in mri_dict[patient][study]:\n",
    "            seriesDescripiton = dcmread(mri_dict[patient][study][series][0]['dcmPath']).SeriesDescription\n",
    "            seriesDescripiton = seriesDescripiton.replace('/',' ')\n",
    "            path = 'categorized/'+ patientFolder+ '/MRI/'+ series + ' (' + seriesDescripiton + ')'\n",
    "            labelPath = 'categorized/'+ patientFolder+ '/MRI/'+ series + ' (' + seriesDescripiton + ')' + '/label/'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            if not os.path.exists(labelPath):\n",
    "                os.makedirs(labelPath)\n",
    "            for c,v in enumerate(mri_dict[patient][study][series]):\n",
    "                shutil.copy(v['dcmPath'],path+ '/'+ str(c+1).zfill(3)+ '.dcm')\n",
    "                width = dcmread(v['dcmPath']).pixel_array.shape[0]\n",
    "                height = dcmread(v['dcmPath']).pixel_array.shape[1]\n",
    "                labelImg = Image.new('RGBA', (width, height))\n",
    "                if(v['labelPath']!='NA'):                    \n",
    "                    labelImg = getLabeledImageWithJson(v['labelPath'])\n",
    "                labelImg.save(labelPath + str(c+1).zfill(3) + '.png')                  \n",
    "                \n",
    "for patient in pet_dict:\n",
    "    for study in pet_dict[patient]:\n",
    "        for series in pet_dict[patient][study]:\n",
    "            seriesDescripiton = dcmread(pet_dict[patient][study][series][0]['dcmPath']).SeriesDescription\n",
    "            seriesDescripiton = seriesDescripiton.replace('/',' ')\n",
    "            path = 'categorized/'+ patientFolder+ '/PET/'+ series + ' (' + seriesDescripiton + ')'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            for c,v in enumerate(pet_dict[patient][study][series]):\n",
    "                shutil.copy(v['dcmPath'],path+ '/'+ str(c+1).zfill(3)+ '.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "32720a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert MRI dicom to png \n",
    "import dicom2jpg\n",
    "mriDicomFolder = 'categorized/005/MRI/6 (t2_tse_dark-fluid_fs_tra+C)/'\n",
    "dicom2jpg.dicom2png(mriDicomFolder, target_root=mriDicomFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "acf96cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert PET dicom to png \n",
    "import dicom2jpg\n",
    "petDicomFolder = 'categorized/005/PET/1353 (FDG WBS PET CT Axial)/'\n",
    "dicom2jpg.dicom2png(petDicomFolder, target_root=petDicomFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "120247a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files (因轉換後檔案名稱在排序上有問題，需要重新命名)\n",
    "startNum = 7\n",
    "renameFolder = 'categorized/001/PET/1353 (FDG WBS PET CT Axial)/png/'\n",
    "files = glob.glob(renameFolder + \"*.png\")\n",
    "files.sort(key=lambda x: len(x), reverse=False)\n",
    "for c,v in enumerate(files):\n",
    "    os.rename(v, renameFolder + str(c+startNum).zfill(3) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to remove hand from PET image\n",
    "ds= io.imread('C:/Users/Justin/Desktop/MRI/pet/gray/003/040.png')\n",
    "cols = ds.shape[0]\n",
    "rows = ds.shape[1]\n",
    "p = 0\n",
    "for i in range(cols):\n",
    "    for j in range(rows//2,rows):\n",
    "        if(ds[j][i]==0):\n",
    "            p = j\n",
    "            break\n",
    "    for k in range(p,rows):\n",
    "        ds[k][i]=0\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows//2,0,-1):\n",
    "        if(ds[j][i]==0):\n",
    "            p = j\n",
    "            break\n",
    "    for k in range(p,0,-1):\n",
    "        ds[k][i]=0\n",
    "\n",
    "plt.imshow(ds,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar image\n",
    "from image_similarity_measures.quality_metrics import rmse,ssim,fsim,sre\n",
    "flairImg = cv2.imread('categorized/005/MRI/6 (t2_tse_dark-fluid_fs_tra+C)/png/025.png')\n",
    "flairImg = cv2.resize(flairImg, (512, 512))\n",
    "petPaths = glob.glob('pet/005/*.png')\n",
    "\n",
    "similarityDict = []\n",
    "print('No,SSIM,FSIM,RMSE,SRE,PHash')\n",
    "for i in range(28,40):\n",
    "    img2 = cv2.imread(petPaths[i])\n",
    "    _ssim = ssim(flairImg,img2)\n",
    "    _fsim = fsim(flairImg,img2)\n",
    "    _rmse = rmse(flairImg,img2)\n",
    "    _sre = sre(flairImg,img2)\n",
    "    _pHash = cmpHash(pHash(flairImg),pHash(img2))\n",
    "    print(str(i+1),end=',')\n",
    "    print(str(_ssim),end=',')\n",
    "    print(str(_fsim),end=',')\n",
    "    print(str(_rmse),end=',')\n",
    "    print(str(_sre),end=',')\n",
    "    print(str(_pHash))\n",
    "    similarityDict.append({'No':i+1,'SSIM':_ssim,'FSIM':_fsim,'RMSE':_rmse,'SRE':_sre,'PHash':_pHash})\n",
    "similarityDict.sort(key=lambda x:x['SSIM'],reverse=True)\n",
    "print(similarityDict[0]['No'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4c61d77",
   "metadata": {},
   "source": [
    "ImageRegistration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fdfc717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mriPath = 'categorized/002/MRI/6 (t2_tse_dark-fluid_fs_tra+C)/'\n",
    "ctPath = 'categorized/002/PET/3 (WB Standard)/'\n",
    "patientNum = '002'\n",
    "startImgNum = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "44fac72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n"
     ]
    }
   ],
   "source": [
    "# 挑選MRI内插後與CT位置對應的圖像\n",
    "# 14*(n-1)+n\n",
    "mriSliceNum = 25    #mri對應號碼\n",
    "ctSliceNum = 35    #ct對應號碼\n",
    "start = 14*(mriSliceNum-1)+mriSliceNum\n",
    "src_path = glob.glob('C:/Users/Justin/Desktop/high_order_slices_interpolation_for-medical_images/interpolated/mri/'+patientNum+'/*.png')\n",
    "dst_path = 'corresponded/'+patientNum+'/label/'\n",
    "if not os.path.exists(dst_path):\n",
    "    os.makedirs(dst_path)\n",
    "n = 0\n",
    "m = ctSliceNum\n",
    "print(start)\n",
    "for i in range(start,0,-1):\n",
    "    if(n%28==0):\n",
    "        shutil.copy(src_path[i],dst_path+str(m).zfill(3)+'.png')\n",
    "        n=0\n",
    "        m-=1\n",
    "    n+=2\n",
    "m = ctSliceNum\n",
    "for i in range(start,len(src_path)):\n",
    "    if(n%28==0):\n",
    "        shutil.copy(src_path[i],dst_path+str(m).zfill(3)+'.png')\n",
    "        n=0\n",
    "        m+=1\n",
    "    n+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理内插后的label（<0.5設爲0，>=0.5設爲1）\n",
    "patientNum = '005'\n",
    "startImgNum = 10\n",
    "labelFolder = glob.glob('corresponded/'+patientNum+'/label/shaped/*.png')\n",
    "savePath = 'corresponded/'+patientNum+'/label/shaped/'\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "for i in range(len(labelFolder)):\n",
    "    label = io.imread(labelFolder[i])\n",
    "    label[label<127] = 0\n",
    "    label[label>=127] = 255\n",
    "    io.imsave(savePath+str(i+startImgNum).zfill(3)+'.png',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算MRI與PET之間的voxel物理大小 與 兩者之間的縮放比例\n",
    "mri = dcmread(mriPath + '001.dcm')\n",
    "ct = dcmread(ctPath + '001.dcm')\n",
    "mriPixelSpacing = mri.PixelSpacing\n",
    "ctPixelSpacing = ct.PixelSpacing\n",
    "print(mri.pixel_array.shape)\n",
    "print('MRI: ' + str(mriPixelSpacing))\n",
    "print(ct.pixel_array.shape)\n",
    "print('CT: ' + str(ctPixelSpacing))\n",
    "print('Ratio: ' + str(mriPixelSpacing[0]/ctPixelSpacing[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate and rescale mr images\n",
    "from skimage.transform import rotate,rescale,resize\n",
    "from scipy.ndimage import shift\n",
    "mirFolder = mriPath\n",
    "ctFolder = ctPath\n",
    "correspondedMRIPaths = glob.glob('corresponded/'+patientNum+'/label/*.png')\n",
    "saveFolder = 'corresponded/'+patientNum+'/label/shaped/'\n",
    "if not os.path.exists(saveFolder):\n",
    "    os.makedirs(saveFolder)\n",
    "\n",
    "mri = dcmread(mirFolder + '001.dcm')\n",
    "mri2 = dcmread(mirFolder + '002.dcm')\n",
    "ct = dcmread(ctFolder + '001.dcm')\n",
    "mriPixelSpacing = mri.PixelSpacing\n",
    "ctPixelSpacing = ct.PixelSpacing\n",
    "imgSize = ct.pixel_array.shape[0]   \n",
    "rotateVal = 4.7\n",
    "shiftX = -11\n",
    "shiftY = 0\n",
    "mmRescaleVal = mriPixelSpacing[0]/ctPixelSpacing[0]  #物理比例\n",
    "deltaXVal = (mri2.ImagePositionPatient[0] - mri.ImagePositionPatient[0]) / mri.PixelSpacing[0]  #mm轉換成像素單位\n",
    "deltaYVal = (mri2.ImagePositionPatient[1] - mri.ImagePositionPatient[1]) / mri.PixelSpacing[0]  #mm轉換成像素單位\n",
    "deltaX = 0\n",
    "deltaY = 0\n",
    "print(mmRescaleVal)\n",
    "for i in range(0,len(correspondedMRIPaths)):\n",
    "    img = io.imread(correspondedMRIPaths[i])\n",
    "    img = rescale(img,mmRescaleVal)\n",
    "    img = rotate(img,rotateVal)\n",
    "    img = enlargeImageLayout(img,(512,512))\n",
    "    img = shift(img,(shiftY,shiftX))\n",
    "    io.imsave(saveFolder+str(i+startImgNum).zfill(3)+'.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cab183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對應好的MRI與標記檔進行縮放，對應到50%PET的大小\n",
    "from skimage.transform import rescale\n",
    "from skimage.color import rgb2gray\n",
    "patientNum = '005'\n",
    "startImgNum = 10\n",
    "rescaleVal = 1.6\n",
    "outputSize = 320\n",
    "correspondedMRIPaths = glob.glob('corresponded/'+patientNum+'/shaped/*.png')\n",
    "correspondedLabelPaths = glob.glob('corresponded/'+patientNum+'/label/shaped/*.png')\n",
    "petPaths = glob.glob('corresponded/'+patientNum+'/pet/*.png')\n",
    "saveMriPath = 'corresponded/'+patientNum+'/shaped/'\n",
    "saveLabelPath = 'corresponded/'+patientNum+'/label/shaped/'\n",
    "savePetPath = 'corresponded/'+patientNum+'/pet/'\n",
    "saveGrayPetPath = 'corresponded/'+patientNum+'/pet/gray/'\n",
    "if not os.path.exists(saveGrayPetPath):\n",
    "    os.makedirs(saveGrayPetPath)\n",
    "for i in range(len(correspondedMRIPaths)):\n",
    "    mri = io.imread(correspondedMRIPaths[i])\n",
    "    label = io.imread(correspondedLabelPaths[i])\n",
    "    pet = io.imread(petPaths[i])\n",
    "    mri = rescale(mri,rescaleVal)\n",
    "    label = rescale(label,rescaleVal)\n",
    "    mriStartPos = (mri.shape[0] - outputSize) // 2\n",
    "    petStartPos = (pet.shape[0] - outputSize) // 2\n",
    "    mri = mri[mriStartPos:mriStartPos+outputSize,mriStartPos:mriStartPos+outputSize]\n",
    "    label = label[mriStartPos:mriStartPos+outputSize,mriStartPos:mriStartPos+outputSize]\n",
    "    pet = pet[petStartPos:petStartPos+outputSize,petStartPos:petStartPos+outputSize,:]\n",
    "    grayPet = rgb2gray(pet)\n",
    "    io.imsave(saveMriPath+str(i+startImgNum).zfill(3)+'.png',mri)\n",
    "    io.imsave(saveLabelPath+str(i+startImgNum).zfill(3)+'.png',label)\n",
    "    io.imsave(savePetPath+str(i+startImgNum).zfill(3)+'.png',pet)\n",
    "    io.imsave(saveGrayPetPath+str(i+startImgNum).zfill(3)+'.png',grayPet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab072a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert color pet to gray pet and save\n",
    "patientNum = '005'\n",
    "startImgNum = 13\n",
    "petPaths = glob.glob('corresponded/'+patientNum+'/pet/*.png')\n",
    "saveGrayPetPath = 'corresponded/'+patientNum+'/pet/gray/'\n",
    "if not os.path.exists(saveGrayPetPath):\n",
    "    os.makedirs(saveGrayPetPath)\n",
    "for i in range(len(petPaths)):\n",
    "    pet = io.imread(petPaths[i])\n",
    "    grayPet = rgb2gray(pet)\n",
    "    io.imsave(saveGrayPetPath+str(i+startImgNum).zfill(3)+'.png',grayPet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d38781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#superimpose label to mri and pet then save image\n",
    "patientNum = '004'\n",
    "startImgNum = 10\n",
    "correspondedMRIPaths = glob.glob('corresponded/'+patientNum+'/shaped/*.png')\n",
    "correspondedLabelPaths = glob.glob('corresponded/'+patientNum+'/label/shaped/contour/*.png')\n",
    "petPaths = glob.glob('corresponded/'+patientNum+'/pet/*.png')\n",
    "cols = 2\n",
    "rows = len(petPaths)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "for n_slice in range(rows):\n",
    "    mri = Image.open(correspondedMRIPaths[n_slice])\n",
    "    label = Image.open(correspondedLabelPaths[n_slice])\n",
    "    pet = Image.open(petPaths[n_slice])\n",
    "    mri.paste(label,(0,0),mask=label)\n",
    "    pet.paste(label,(0,0),mask=label)\n",
    "    ax=fig.add_subplot(1,cols,1)\n",
    "    ax.set_title(\"MRI\",fontsize=22)\n",
    "    plt.imshow(mri,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(1,cols,2)\n",
    "    ax.set_title(\"PET\",fontsize=22)\n",
    "    plt.imshow(pet,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(str(n_slice+1).zfill(3) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw comparison of FLAIR and shaped PET\n",
    "patientNum = '003'\n",
    "mriFolder = glob.glob('corresponded/'+patientNum+'/shaped/*.png')\n",
    "petFolder = glob.glob('corresponded/'+patientNum+'/pet/*.png')\n",
    "labelFolder = glob.glob('corresponded/'+patientNum+'/label/shaped/*.png')\n",
    "cols = 3\n",
    "rows = len(mriFolder)\n",
    "fig = plt.figure(figsize=(6, 100))\n",
    "for n_slice in range(rows):\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+1)\n",
    "    img1 = io.imread(mriFolder[n_slice])\n",
    "    plt.imshow(img1,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+2)\n",
    "    img2 = io.imread(petFolder[n_slice])\n",
    "    plt.imshow(img2,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+3)\n",
    "    img3 = io.imread(labelFolder[n_slice])\n",
    "    plt.imshow(img3,cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6d1f277",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6adb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print deltaX, deltaY and deltaZ of slices of dicom\n",
    "dcmFolder = glob.glob('categorized/004/MRI/601 (T2W_FLAIR_FS+C(Gadovist))/*dcm')\n",
    "dss = [dcmread(i) for i in dcmFolder]\n",
    "preX = 0\n",
    "preY = 0\n",
    "preZ = 0\n",
    "for i in dss:\n",
    "    # print('SliceLocation: ' + str(i.ImagePositionPatient))\n",
    "    pos = i.ImagePositionPatient\n",
    "    curX = pos[0]\n",
    "    curY = pos[1]\n",
    "    curZ = pos[2]\n",
    "    print(str(curX - preX)+', '+str(curY - preY)+ ', ' + str(curZ - preZ))\n",
    "    preX = curX\n",
    "    preY = curY\n",
    "    preZ = curZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9ab5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataset for input->(SIZE,SIZE,SLICE,CHANNEL)\n",
    "SIZE = 240\n",
    "DEPTH = 48\n",
    "CHANNEL = 3\n",
    "patientNum = '001'\n",
    "saveFolder = 'mri_training_dataset/'\n",
    "t1Folder = glob.glob('categorized/004/MRI/801 (T1W_FFE_FS+CM(Gadovist))/*.dcm')\n",
    "t2Folder =  glob.glob('categorized/004/MRI/401 (T2W_FS +CM(Gadovist))/*.dcm')\n",
    "flairFolder =  glob.glob('categorized/004/MRI/601 (T2W_FLAIR_FS+C(Gadovist))/*.dcm')\n",
    "labelFolder = glob.glob('categorized/004/MRI/label/*.png')\n",
    "\n",
    "t1 = np.zeros((SIZE,SIZE,DEPTH))\n",
    "t2 = np.zeros((SIZE,SIZE,DEPTH))\n",
    "flair = np.zeros((SIZE,SIZE,DEPTH))\n",
    "seg = np.zeros((SIZE,SIZE,DEPTH))\n",
    "\n",
    "for c, i in enumerate(t1Folder):\n",
    "    t1[:,:,c] = cv2.resize(rescaleFrom0to255(dcmread(i).pixel_array), (SIZE,SIZE))\n",
    "for c, i in enumerate(t2Folder):\n",
    "    t2[:,:,c] = cv2.resize(rescaleFrom0to255(dcmread(i).pixel_array), (SIZE,SIZE))\n",
    "for c, i in enumerate(flairFolder):\n",
    "    flair[:,:,c] = cv2.resize(rescaleFrom0to255(dcmread(i).pixel_array), (SIZE,SIZE))\n",
    "for c, i in enumerate(labelFolder):\n",
    "    seg[:,:,c] = cv2.resize(io.imread(i)[:,:,2], (SIZE,SIZE))\n",
    "seg[seg!=0] = 1\n",
    "nib.save(nib.Nifti1Image(t1, affine=np.eye(4)), saveFolder+'mri_'+patientNum+'_t1.nii')\n",
    "nib.save(nib.Nifti1Image(t2, affine=np.eye(4)), saveFolder+'mri_'+patientNum+'_t2.nii')\n",
    "nib.save(nib.Nifti1Image(flair, affine=np.eye(4)), saveFolder+'mri_'+patientNum+'_flair.nii')\n",
    "nib.save(nib.Nifti1Image(seg, affine=np.eye(4)), saveFolder+'mri_'+patientNum+'_seg.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate nii mri dataset\n",
    "seg = nib.load('mri_training_dataset/mri_004_seg.nii').get_fdata()\n",
    "flair = nib.load('mri_training_dataset/mri_004_flair.nii').get_fdata()\n",
    "t1 = nib.load('mri_training_dataset/mri_004_t1.nii').get_fdata()\n",
    "t2 = nib.load('mri_training_dataset/mri_004_t2.nii').get_fdata()\n",
    "cols=4\n",
    "rows=48\n",
    "fig = plt.figure(figsize=(8, 100))\n",
    "for n_slice in range(rows):\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+1)\n",
    "    ax.title.set_text('flairs')\n",
    "    plt.imshow(flair[:,:,n_slice], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+2)\n",
    "    ax.title.set_text('t1')\n",
    "    plt.imshow(t1[:,:,n_slice], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+3)\n",
    "    ax.title.set_text('t2')\n",
    "    plt.imshow(t2[:,:,n_slice], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+4)\n",
    "    ax.title.set_text('Label')\n",
    "    plt.imshow(seg[:,:,n_slice])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 嘗試用標記檔配對dcm檔\n",
    "path = \"20221005/002/002-MR\"\n",
    "files = glob.glob(path + \"/*.dcm\")\n",
    "pngs = glob.glob(path + \"/*0.png\")\n",
    "labes = glob.glob(path + \"/*anno.png\")\n",
    "cols = 3\n",
    "rows = len(pngs)\n",
    "fig = plt.figure(figsize=(rows/6,rows*2))\n",
    "for i in range(len(pngs)):\n",
    "    sopID = str(pngs[i].split(path)[1][1:-6]) #去除資料夾字段及後綴，保留UID\n",
    "    for j in files:\n",
    "        f = dcmread(j)\n",
    "        if(str(f.SOPInstanceUID) == sopID):\n",
    "            ax1 = fig.add_subplot(rows,cols,(i*cols)+1)\n",
    "            ax1.title.set_text('dcm/series: ' + str(f.SeriesNumber))\n",
    "            plt.imshow(f.pixel_array)\n",
    "            plt.axis('off')\n",
    "            ax2 = fig.add_subplot(rows,cols,(i*cols)+2)\n",
    "            ax2.title.set_text('png')\n",
    "            plt.imshow(Image.open(pngs[i]))\n",
    "            plt.axis('off')\n",
    "            ax3 = fig.add_subplot(rows,cols,(i*cols)+3)\n",
    "            ax3.title.set_text('label')\n",
    "            plt.imshow(Image.open(labes[i]))\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8394d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nii_to_png(niifile):    \n",
    "    img = nib.load(niifile)\n",
    "    fdata = img.get_fdata()\n",
    "    (x,y,z) = fdata.shape\n",
    "    for i in range(z):\n",
    "        slice_pic = fdata[:,:,i]\n",
    "        plt.imsave('nii_to_png/img' + str(i+1) + '.png', slice_pic, cmap='gray')\n",
    "\n",
    "TRAIN_DATASET_PATH = ''\n",
    "test_image = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001_seg.nii')\n",
    "print(test_image)\n",
    "test_image = test_image.get_fdata()\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(test_image.shape[2]):\n",
    "    plt.subplot(11,15,i+1)\n",
    "    plt.imshow(test_image[:,:,i])\n",
    "    plt.axis('off')\n",
    "\n",
    "if(not os.path.exists('nii_to_png')):\n",
    "    os.mkdir('nii_to_png')\n",
    "save_nii_to_png(TRAIN_DATASET_PATH + 'BraTS20_Training_001_seg.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0273f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw comparison of original and interpolated images\n",
    "cols = 3\n",
    "rows = 47\n",
    "\n",
    "fig = plt.figure(figsize=(6,100))\n",
    "for n_slice in range(rows-1):\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+1)\n",
    "    # ax.title.set_text(str(n_slice*2))\n",
    "    ax.title.set_text('interpolated')\n",
    "    plt.imshow(flair_interpolated[:,:,(n_slice*4)+1],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+2)\n",
    "    ax.title.set_text('interpolated')\n",
    "    plt.imshow(flair_interpolated[:,:,(n_slice*4)+2],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+3)\n",
    "    # ax.title.set_text(str((n_slice*2)+2))\n",
    "    ax.title.set_text('interpolated')\n",
    "    plt.imshow(flair_interpolated[:,:,(n_slice*4)+3],cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b026918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate images similarity\n",
    "from image_similarity_measures.quality_metrics import ssim\n",
    "\n",
    "slices = 47\n",
    "total_ssim = 0\n",
    "for i in range(slices-1):\n",
    "    a = (interpolate_output[:,:,(i*4)+1]/np.max(interpolate_output[:,:,(i*4)+1]))*255\n",
    "    b = (flair_interpolated[:,:,(i*4)+1])*255\n",
    "    total_ssim += ssim(a,b)\n",
    "    a = (interpolate_output[:,:,(i*4)+2]/np.max(interpolate_output[:,:,(i*4)+2]))*255\n",
    "    b = (flair_interpolated[:,:,(i*4)+2])*255\n",
    "    total_ssim += ssim(a,b)\n",
    "    a = (interpolate_output[:,:,(i*4)+3]/np.max(interpolate_output[:,:,(i*4)+3]))*255\n",
    "    b = (flair_interpolated[:,:,(i*4)+3])*255\n",
    "    total_ssim += ssim(a,b)\n",
    "print(total_ssim)\n",
    "print(\"total_similarity: \"+  str(total_ssim/((slices-1)*3)))\n",
    "# fig = plt.figure(figsize=(4,2))\n",
    "# ax=fig.add_subplot(1,2,1)\n",
    "# plt.imshow(a,cmap='gray')\n",
    "# plt.axis('off')\n",
    "# ax=fig.add_subplot(1,2,2)\n",
    "# plt.imshow(b,cmap='gray')\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c06657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare original mri, our method and registration method\n",
    "from skimage.transform import rotate\n",
    "mri = glob.glob('categorized/005/MRI/6 (t2_tse_dark-fluid_fs_tra+C)/*.dcm')\n",
    "registered = nib.load('../registered/001_6dof.nii.gz').get_fdata()\n",
    "shaped = glob.glob('./pet/005/corresponded/shaped/*.png')\n",
    "rows = registered.shape[2]\n",
    "cols = 3\n",
    "print(np.unique(registered[:,:,25]))\n",
    "print(registered[:,:,25].shape)\n",
    "io.imshow(registered[:,:,25],cmap='gray')\n",
    "fig = plt.figure(figsize=(6,100))\n",
    "for n_slice in range(rows-1):\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+1)\n",
    "    plt.imshow(dcmread(mri[n_slice]).pixel_array,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+2)\n",
    "    plt.imshow(io.imread(shaped[n_slice]),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+3)\n",
    "    plt.imshow(rotate(registered[:,:,rows-1-n_slice][::-1,:],-90),cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save registered nib to png\n",
    "from skimage.transform import rotate\n",
    "ds = dcmread('./categorized/005/PET/3 (WB Standard)/001.dcm')\n",
    "folder = './registered/005_6dof.nii.gz'\n",
    "registered = nib.load(folder).get_fdata()\n",
    "sn = registered.shape[2]\n",
    "saveFolder = folder[:-7]\n",
    "if not os.path.exists(saveFolder):\n",
    "    os.mkdir(saveFolder)\n",
    "for i in range(registered.shape[2]):\n",
    "    save_img = apply_ct_window(rotate(registered[:,:,i][::-1,:],-90),[ds.WindowWidth,ds.WindowCenter])\n",
    "    io.imsave(saveFolder + '/' + str(sn).zfill(3) + '.png',save_img)\n",
    "    sn-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save petct and label to nii for training\n",
    "from skimage.transform import resize\n",
    "patientNum = '005'\n",
    "pets = glob.glob('./corresponded/' + patientNum + '/pet/gray/*.png')\n",
    "labels = glob.glob('./corresponded/' + patientNum + '/label/shaped/*.png')\n",
    "imgSize = 320\n",
    "slicesNum = 48\n",
    "output = np.zeros((imgSize,imgSize,slicesNum))\n",
    "seg = np.zeros((imgSize,imgSize,slicesNum))\n",
    "for i in range(slicesNum):\n",
    "    if(i>=len(pets)):\n",
    "        output[:,:,i] = np.zeros((imgSize,imgSize))\n",
    "        seg[:,:,i] = np.zeros((imgSize,imgSize))\n",
    "    else:\n",
    "        img = io.imread(pets[i])\n",
    "        label = io.imread(labels[i])[:,:]\n",
    "        print(np.unique(label))\n",
    "        if(img.shape[0]>256):\n",
    "            img = rescaleFrom0to255(resize(img,(imgSize,imgSize)))\n",
    "        if(label.shape[0]>256):\n",
    "            label = rescaleFrom0to255(resize(label,(imgSize,imgSize)))\n",
    "        output[:,:,i] = img\n",
    "        seg[:,:,i] = label\n",
    "seg[seg!=0] = 1\n",
    "nib.save(nib.Nifti1Image(output, affine=np.eye(4)), 'pet_training_dataset/' + patientNum + '_pet.nii.gz')\n",
    "nib.save(nib.Nifti1Image(seg, affine=np.eye(4)), 'pet_training_dataset/' + patientNum + '_pet_seg.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fee0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate saved pet nib (compare with original mri)\n",
    "patientNum = '001'\n",
    "mri = glob.glob('./corresponded/'+patientNum+'/shaped/*.png')\n",
    "pet = nib.load('./pet_training_dataset/'+patientNum+'_pet.nii.gz').get_fdata()\n",
    "seg = nib.load('./pet_training_dataset/'+patientNum+'_pet_seg.nii.gz').get_fdata()\n",
    "print(pet.shape)\n",
    "print(seg.shape)\n",
    "print(np.unique(seg))\n",
    "cols = 3\n",
    "rows = 48\n",
    "fig = plt.figure(figsize=(6,100))\n",
    "for n_slice in range(rows):\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+1)\n",
    "    plt.imshow(io.imread(mri[n_slice]),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+2)\n",
    "    plt.imshow(pet[:,:,n_slice],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+3)\n",
    "    plt.imshow(seg[:,:,n_slice])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#superimpose MRI and PET with label and save\n",
    "mriFolder = \"./categorized/004/MRI/601 (T2W_FLAIR_FS+C(Gadovist))/png/\"\n",
    "petFolder = \"../registered/png/\"\n",
    "labelFolder = \"./categorized/004/MRI/label/\"\n",
    "mri_path = glob.glob(mriFolder + '*.png')\n",
    "pet_path = glob.glob(petFolder + \"*.png\")\n",
    "labels_path = glob.glob(labelFolder + '*.png')\n",
    "mriLabeledImages = []\n",
    "petLabeledImages = []\n",
    "sliceSize = len(mri_path)\n",
    "for i in range(sliceSize):\n",
    "    image = Image.open(mri_path[i])\n",
    "    rgbImage = Image.new(\"RGB\", image.size)\n",
    "    rgbImage.paste(image)\n",
    "    label = Image.open(labels_path[i])\n",
    "    rgbImage.paste(label,(0,0),mask=label)\n",
    "    mriLabeledImages.append(rgbImage)\n",
    "    image = Image.open(pet_path[sliceSize-i-1])\n",
    "    rgbImage = Image.new(\"RGB\", image.size)\n",
    "    rgbImage.paste(image)\n",
    "    rgbImage.paste(label,(0,0),mask=label)\n",
    "    petLabeledImages.append(rgbImage)\n",
    "\n",
    "rows = 1\n",
    "cols = 2\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "for n_slice in range(sliceSize):\n",
    "    ax=fig.add_subplot(rows,cols,1)\n",
    "    ax.set_title(\"MRI\",fontsize=22)\n",
    "    plt.imshow(mriLabeledImages[n_slice],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,2)\n",
    "    ax.set_title(\"PET\",fontsize=22)\n",
    "    plt.imshow(petLabeledImages[n_slice],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(str(n_slice+1).zfill(3) + '.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9369be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "c:\\ProgramData\\Anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pydicom import dcmread\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io, color\n",
    "from skimage.transform import resize\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "\n",
    "import math\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import nibabel as nib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2b8ec83",
   "metadata": {},
   "source": [
    "## Define Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d143419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw dicom images with metadata info\n",
    "from datetime import datetime\n",
    "def drawCategorizedImages(folderPath, dict, fontsize=10, fontfamily='MingLiU'):\n",
    "    for patient in dict:\n",
    "        for study in dict[patient]:\n",
    "            for series in dict[patient][study]:\n",
    "                fileList = dict[patient][study][series]\n",
    "                imagesList = []\n",
    "                for file in fileList:\n",
    "                    imagesList.append(dcmread(folderPath + file['dcmPath']))\n",
    "                imagesList.sort(key=lambda x: x.InstanceNumber, reverse=False) # sort image by instance number\n",
    "                quantity = len(imagesList)\n",
    "                cols = 10\n",
    "                rows = math.ceil(quantity/cols)\n",
    "                rows = rows + int(rows/6) + 1 # add blank rows to place text\n",
    "                fig = plt.figure(figsize=(cols*2,rows*2))\n",
    "                flag = True\n",
    "                for i in range(quantity):\n",
    "                    ds = imagesList[i]\n",
    "\n",
    "                    if (\"PixelData\" in ds):\n",
    "                        #add text only once\n",
    "                        if flag:\n",
    "                            plt.text(0.01,0.14,\"PatientName: \" + str(ds.PatientName), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.01,0.11,\"PatientID: \" + str(ds.PatientID), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.01,0.08,\"Sex: \" + str(ds.PatientSex), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.33,0.14,\"InstitutionName: \" + ds.InstitutionName if ds.InstitutionName != \"\" else \"InstitutionName: None\", fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.33,0.11,\"StudyDescription: \" + ds.StudyDescription, fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.33,0.08,\"StudyID: \" + ds.StudyID, fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.14,\"SeriesNumber: \" + str(ds.SeriesNumber), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.11,\"SeriesDescription: \" + str(ds.SeriesDescription), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.08,\"AccessionNumber: \" + ds.AccessionNumber, fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.05,\"AcquisitionDate: \" + str(datetime.strptime(ds.AcquisitionDate, '%Y%m%d').date()), fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            plt.text(0.66,0.02,\"AcquisitionTime: \" + ds.AcquisitionTime, fontsize=fontsize, fontfamily=fontfamily)\n",
    "#                             plt.text(0.66,0.085,\"SliceThickness: \" + str(math.ceil(ds.SliceThickness)) + \"mm\", fontsize=fontsize, fontfamily=fontfamily)\n",
    "#                             plt.text(0.66,0.06,\"SliceLocation: \" + str(math.ceil(ds.SliceLocation)) + \"mm\", fontsize=fontsize, fontfamily=fontfamily)\n",
    "                            flag = False   \n",
    "\n",
    "                        fig.add_subplot(rows, cols, i+1)\n",
    "                        if(len(ds.pixel_array.shape)==3):\n",
    "                            plt.imshow(ds.pixel_array[:,:,1])\n",
    "                        else:\n",
    "                            plt.imshow(ds.pixel_array)\n",
    "                        plt.axis('off')\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def showImagesWithPyPlot(images,cmap):\n",
    "    quantity = len(images)\n",
    "    cols = 9\n",
    "    rows = math.ceil(quantity/cols)\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=(22,2.5*rows))\n",
    "    for i in range(quantity):\n",
    "        ax[i//cols][i%cols].imshow(images[i],cmap=cmap)\n",
    "        ax[i//cols][i%cols].axis('off')\n",
    "\n",
    "def showNiftiImagesWithPyPlot(nifti,cmap):\n",
    "    quantity = nifti.shape[2]\n",
    "    cols = 9\n",
    "    rows = math.ceil(quantity/cols)\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=(22,2.5*rows))\n",
    "    for i in range(quantity):\n",
    "        ax[i//cols][i%cols].imshow(nifti[:,:,i],cmap=cmap)\n",
    "        ax[i//cols][i%cols].axis('off')\n",
    "\n",
    "##################################################################\n",
    "\n",
    "#使用json檔案畫實心標記區域\n",
    "def fillMissingPoint(segments):\n",
    "    startX = segments[0]['a'][0]\n",
    "    startY = segments[0]['a'][1]\n",
    "    endX = segments[len(segments)-1]['b'][0]\n",
    "    endY = segments[len(segments)-1]['b'][1]\n",
    "    width = segments[0]['width']\n",
    "    distanceX = abs(endX-startX)\n",
    "    distanceY = abs(endY-startY)    \n",
    "    stepX = 1\n",
    "    if(distanceX<=distanceY and distanceY!=0):\n",
    "        stepX = distanceX/distanceY\n",
    "    stepY = 1\n",
    "    if(distanceY<=distanceX and distanceX!=0):\n",
    "        stepY = distanceY/distanceX\n",
    "    if(endX >= startX and endY >= startY):\n",
    "        while(endX >= startX and endY >= startY):\n",
    "            a = [endX,endY]\n",
    "            endX-=stepX\n",
    "            endY-=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    elif(endX >= startX and endY <= startY):\n",
    "        while(endX >= startX and endY <= startY):\n",
    "            a = [endX,endY]\n",
    "            endX-=stepX\n",
    "            endY+=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    elif(endX <= startX and endY <= startY):\n",
    "        while(endX <= startX and endY <= startY):\n",
    "            a = [endX,endY]\n",
    "            endX+=stepX\n",
    "            endY+=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    elif(endX <= startX and endY >= startY):\n",
    "        while(endX <= startX and endY >= startY):\n",
    "            a = [endX,endY]\n",
    "            endX+=stepX\n",
    "            endY-=stepY\n",
    "            b = [endX,endY]\n",
    "            segments.append({'a':a,'b':b,'width':width})\n",
    "    return segments\n",
    "\n",
    "def getLabeledImageWithJson(jsonPath):\n",
    "    file = open(jsonPath)\n",
    "    data = json.load(file)\n",
    "    image = Image.new(\"RGB\", data['size'])\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    shapes = data['shapes']\n",
    "    for shape in shapes:\n",
    "        segments = shape['segments']\n",
    "        segments = fillMissingPoint(segments)\n",
    "        strokeColor = shape['strokeColor']\n",
    "        for segment in segments:\n",
    "            startEndCoord = [(segment['a'][0], segment['a'][1]),(segment['b'][0], segment['b'][1])]\n",
    "            draw.line(startEndCoord, fill=strokeColor)\n",
    "    \n",
    "    # 找輪廓並填充顔色\n",
    "    grayImage  = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2GRAY)\n",
    "    cnts = cv2.findContours(grayImage, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        cv2.drawContours(grayImage,[c], 0, (255,255,255), -1)\n",
    "\n",
    "    colorImage = cv2.cvtColor(grayImage,cv2.COLOR_GRAY2RGB)\n",
    "    colorImage[np.all(colorImage == (255, 255, 255), axis=-1)] = ImageColor.getcolor(strokeColor, \"RGB\")    \n",
    "    \n",
    "    #convert black background to transparent\n",
    "    _, alpha = cv2.threshold(grayImage, 0, 255, cv2.THRESH_BINARY)\n",
    "    b, g, r = cv2.split(colorImage)\n",
    "    rgba = [b, g, r, alpha]\n",
    "    colorImage = cv2.merge(rgba, 4)\n",
    "    \n",
    "    #convert cv2 to pil format\n",
    "    pilImage = Image.fromarray(colorImage)\n",
    "    return pilImage\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# categorize dicom files with patientID, studyID and seriesID without using dicomdir\n",
    "# 查找自己的json標記檔是否存在，如果不存在label設爲no，否則label設爲json標記檔的路徑\n",
    "def getLabelPath(dcmPath, sopInstanceUID):\n",
    "    jsonFiles = glob.glob(dcmPath.split('\\\\')[0] + \"/*.json\")\n",
    "    for jsonFile in jsonFiles:\n",
    "        if(sopInstanceUID in jsonFile):\n",
    "            return jsonFile\n",
    "    return 'NA'\n",
    "\n",
    "# dict: {patientID->studyID->seriesID->{dcmPath,labelPath}}\n",
    "def getCategorizedDictByFolder(path):\n",
    "    files = glob.glob(path + \"*.dcm\")\n",
    "    dict = {}\n",
    "    for file in files:\n",
    "        ds = dcmread(file)\n",
    "        patientID = ds.PatientID\n",
    "        studyID = ds.StudyID\n",
    "        seriesID = str(ds.SeriesNumber)\n",
    "        labelPath = getLabelPath(file, ds.SOPInstanceUID)\n",
    "        data = {'dcmPath':file,'labelPath':labelPath}\n",
    "        if patientID in dict:\n",
    "            if studyID in dict[patientID]:\n",
    "                if seriesID in dict[patientID][studyID]:\n",
    "                    dict[patientID][studyID][seriesID].append(data)\n",
    "                else:\n",
    "                    dict[patientID][studyID][seriesID] = [data]\n",
    "            else:\n",
    "                dict[patientID][studyID] = {seriesID:[data]}\n",
    "        else:\n",
    "            dict[patientID] = {studyID:{seriesID:[data]}}\n",
    "\n",
    "    # sort dict by InstanceNumber\n",
    "    for patient in dict:\n",
    "            for study in dict[patient]:\n",
    "                for series in dict[patient][study]:\n",
    "                    dict[patient][study][series].sort(key=lambda x: dcmread(x['dcmPath']).InstanceNumber, reverse=False)\n",
    "\n",
    "    return dict\n",
    "\n",
    "def getSeriesIDByName(dict, name):\n",
    "    for patient in dict:\n",
    "        for study in dict[patient]:\n",
    "            for series in dict[patient][study]:\n",
    "                for i in dict[patient][study][series]:\n",
    "                    if(name.lower() in dcmread(i['dcmPath']).SeriesDescription.lower()):\n",
    "                        return series\n",
    "##################################################################\n",
    "\n",
    "# 調整圖像色階\n",
    "def adjust_color_scale(img,Shadow,Highlight):\n",
    "    if Highlight > 255:\n",
    "        Highlight = 255\n",
    "    if Shadow < 0:\n",
    "        Shadow = 0\n",
    "    if Shadow >= Highlight:\n",
    "        Shadow = Highlight - 2\n",
    "    # 转类型\n",
    "    img = np.array(img, dtype=int)\n",
    "    # 计算白场黑场离差\n",
    "    Diff = Highlight - Shadow\n",
    "    # 计算系数\n",
    "    coe = 255.0 / Diff\n",
    "    rgbDiff = img - Shadow\n",
    "    rgbDiff = np.maximum(rgbDiff, 0)\n",
    "    img = rgbDiff * coe\n",
    "    # 四舍五入到整数\n",
    "    img = np.around(img, 0)\n",
    "    # 变为int型\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 計算兩張圖片的相似度（https://www.twblogs.net/a/5ee8804f38b2869e41a03399）\n",
    "\n",
    "# 均值哈希算法\n",
    "def aHash(img):\n",
    "    # 縮放爲8*8\n",
    "    img = cv2.resize(img, (8, 8))\n",
    "    # 轉換爲灰度圖\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # s爲像素和初值爲0，hash_str爲hash值初值爲''\n",
    "    s = 0\n",
    "    hash_str = ''\n",
    "    # 遍歷累加求像素和\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            s = s + gray[i, j]\n",
    "    # 求平均灰度\n",
    "    avg = s / 64\n",
    "    # 灰度大於平均值爲1相反爲0生成圖片的hash值\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if gray[i, j] > avg:\n",
    "                hash_str = hash_str + '1'\n",
    "            else:\n",
    "                hash_str = hash_str + '0'\n",
    "    return hash_str\n",
    "# 差值感知算法\n",
    "def dHash(img):\n",
    "    img = cv2.resize(img, (9, 8))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    hash_str = ''\n",
    "    # 每行前一個像素大於後一個像素爲1，相反爲0，生成哈希\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if gray[i, j] > gray[i, j + 1]:\n",
    "                hash_str = hash_str + '1'\n",
    "            else:\n",
    "                hash_str = hash_str + '0'\n",
    "    return hash_str\n",
    "# 感知哈希算法(pHash)\n",
    "def pHash(img):\n",
    "    img = cv2.resize(img, (32, 32))  # , interpolation=cv2.INTER_CUBIC\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 將灰度圖轉爲浮點型，再進行dct變換\n",
    "    dct = cv2.dct(np.float32(gray))\n",
    "    # opencv實現的掩碼操作\n",
    "    dct_roi = dct[0:8, 0:8]\n",
    "\n",
    "    hash = []\n",
    "    avreage = np.mean(dct_roi)\n",
    "    for i in range(dct_roi.shape[0]):\n",
    "        for j in range(dct_roi.shape[1]):\n",
    "            if dct_roi[i, j] > avreage:\n",
    "                hash.append(1)\n",
    "            else:\n",
    "                hash.append(0)\n",
    "    return hash\n",
    "# Hash值對比\n",
    "def cmpHash(hash1, hash2):\n",
    "    n = 0\n",
    "    # hash長度不同則返回-1代表傳參出錯\n",
    "    if len(hash1)!=len(hash2):\n",
    "        return -1\n",
    "    # 遍歷判斷\n",
    "    for i in range(len(hash1)):\n",
    "        # 不相等則n計數+1，n最終爲相似度\n",
    "        if hash1[i] != hash2[i]:\n",
    "            n = n + 1\n",
    "    return n\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# interpolating between two images\n",
    "import matplotlib.cm as cm\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "def inter(images,t):\n",
    "    # input: \n",
    "    # images: list of arrays/frames ordered according to motion\n",
    "    # t: parameter ranging from 0 to 1 corresponding to first and last frame \n",
    "    # returns: interpolated image\n",
    "\n",
    "    #direction of movement, assumed to be approx. linear \n",
    "    a=np.array(center_of_mass(images[0]))\n",
    "    b=np.array(center_of_mass(images[-1]))\n",
    "\n",
    "    #find index of two nearest frames\n",
    "    arr=np.array([center_of_mass(images[i]) for i in range(len(images))])\n",
    "    v=a+t*(b-a) #convert t into vector \n",
    "    idx1 = (np.linalg.norm((arr - v),axis=1)).argmin()\n",
    "    arr[idx1]=np.array([0,0]) #this is sloppy, should be changed if relevant values are near [0,0]\n",
    "    idx2 = (np.linalg.norm((arr - v),axis=1)).argmin()\n",
    "\n",
    "    if idx1>idx2:\n",
    "        b=np.array(center_of_mass(images[idx1])) #center of mass of nearest contour\n",
    "        a=np.array(center_of_mass(images[idx2])) #center of mass of second nearest contour\n",
    "        tstar=np.linalg.norm(v-a)/np.linalg.norm(b-a) #define parameter ranging from 0 to 1 for interpolation between two nearest frames\n",
    "        im1_shift=shift(images[idx2],(b-a)*tstar) #shift frame 1\n",
    "        im2_shift=shift(images[idx1],-(b-a)*(1-tstar)) #shift frame 2\n",
    "        return im1_shift+im2_shift #return average\n",
    "\n",
    "    if idx1<idx2:\n",
    "        b=np.array(center_of_mass(images[idx2]))\n",
    "        a=np.array(center_of_mass(images[idx1]))\n",
    "        tstar=np.linalg.norm(v-a)/np.linalg.norm(b-a)\n",
    "        im1_shift=shift(images[idx2],-(b-a)*(1-tstar))\n",
    "        im2_shift=shift(images[idx1],(b-a)*(tstar))\n",
    "        return im1_shift+im2_shift\n",
    "\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# convert dicom's pixel array to image looks like what we see on standard DICOM viewers\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut, apply_modality_lut\n",
    "\n",
    "def get_LUT_value_LINEAR_EXACT(data, window, level):\n",
    "    \"\"\"\n",
    "    Adjust according to VOI LUT, window center(level) and width values\n",
    "    not normalized\n",
    "    \"\"\"\n",
    "    data_min = data.min()\n",
    "    data_max = data.max()\n",
    "    data_range = data_max - data_min\n",
    "    data = np.piecewise(data, \n",
    "        [data<=(level-(window)/2),\n",
    "        data>(level+(window)/2)],\n",
    "        [data_min, data_max, lambda data: ((data-level+window/2)/window*data_range)+data_min])\n",
    "    return data\n",
    "\n",
    "def pixel_process(ds, pixel_array):\n",
    "    \"\"\"\n",
    "    Process the images\n",
    "    input image info and original pixeal_array\n",
    "    applying LUTs: Modality LUT -> VOI LUT -> Presentation LUT    \n",
    "    return processed pixel_array, in 8bit; RGB if color\n",
    "    \"\"\"\n",
    "    \n",
    "    ## LUTs: Modality LUT -> VOI LUT -> Presentation LUT\n",
    "    # Modality LUT, Rescale slope, Rescale Intercept\n",
    "    if 'RescaleSlope' in ds and 'RescaleIntercept' in ds:\n",
    "        # try applying rescale slope/intercept\n",
    "        # cannot use INT, because rescale slope could be<1 \n",
    "        rescale_slope = float(ds.RescaleSlope) # int(ds.RescaleSlope)\n",
    "        rescale_intercept = float(ds.RescaleIntercept) #  int(ds.RescaleIntercept)\n",
    "        pixel_array = (pixel_array) * rescale_slope + rescale_intercept\n",
    "    else:\n",
    "        # otherwise, try to apply modality \n",
    "        pixel_array = apply_modality_lut(pixel_array, ds)\n",
    "\n",
    "\n",
    "    # personally prefer sigmoid function than window/level\n",
    "    # personally prefer LINEAR_EXACT than LINEAR (prone to err if small window/level, such as some MR images)\n",
    "    if 'VOILUTFunction' in ds and ds.VOILUTFunction=='SIGMOID':\n",
    "        pixel_array = apply_voi_lut(pixel_array, ds)\n",
    "    elif 'WindowCenter' in ds and 'WindowWidth' in ds:\n",
    "        window_center = ds.WindowCenter\n",
    "        window_width = ds.WindowWidth\n",
    "        # some values may be stored in an array\n",
    "        if type(window_center)==pydicom.multival.MultiValue:\n",
    "            window_center = float(window_center[0])\n",
    "        else:\n",
    "            window_center = float(window_center)\n",
    "        if type(window_width)==pydicom.multival.MultiValue:\n",
    "            window_width = float(window_width[0])\n",
    "        else:\n",
    "            window_width = float(window_width)\n",
    "        pixel_array = get_LUT_value_LINEAR_EXACT(pixel_array, window_width, window_center)\n",
    "    else:\n",
    "        # if there is no window center, window width tag, try applying VOI LUT setting\n",
    "        pixel_array = apply_voi_lut(pixel_array, ds)\n",
    "        \n",
    "    # Presentation VOI\n",
    "    # normalize to 12 bit\n",
    "    pixel_array = ((pixel_array-pixel_array.min())/(pixel_array.max()-pixel_array.min()))\n",
    "    # if PhotometricInterpretation == \"MONOCHROME1\", then inverse; eg. xrays\n",
    "    if 'PhotometricInterpretation' in ds and ds.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        # NOT add minus directly\n",
    "        pixel_array = np.max(pixel_array) - pixel_array\n",
    "    \n",
    "    # conver float -> 12-bit\n",
    "    return pixel_array.astype('float')\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Image shadow and highlight correction\n",
    "def imageCorrection(\n",
    "        img,\n",
    "        shadow_amount_percent, shadow_tone_percent, shadow_radius,\n",
    "        highlight_amount_percent, highlight_tone_percent, highlight_radius,\n",
    "        color_percent\n",
    "):\n",
    "    \"\"\"\n",
    "    Image Shadow / Highlight Correction. The same function as it in Photoshop / GIMP\n",
    "    :param img: input RGB image numpy array of shape (height, width, 3)\n",
    "    :param shadow_amount_percent [0.0 ~ 1.0]: Controls (separately for the highlight and shadow values in the image) how much of a correction to make.\n",
    "    :param shadow_tone_percent [0.0 ~ 1.0]: Controls the range of tones in the shadows or highlights that are modified.\n",
    "    :param shadow_radius [>0]: Controls the size of the local neighborhood around each pixel\n",
    "    :param highlight_amount_percent [0.0 ~ 1.0]: Controls (separately for the highlight and shadow values in the image) how much of a correction to make.\n",
    "    :param highlight_tone_percent [0.0 ~ 1.0]: Controls the range of tones in the shadows or highlights that are modified.\n",
    "    :param highlight_radius [>0]: Controls the size of the local neighborhood around each pixel\n",
    "    :param color_percent [-1.0 ~ 1.0]:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    shadow_tone = shadow_tone_percent * 255\n",
    "    highlight_tone = 255 - highlight_tone_percent * 255\n",
    "\n",
    "    shadow_gain = 1 + shadow_amount_percent * 6\n",
    "    highlight_gain = 1 + highlight_amount_percent * 6\n",
    "\n",
    "    # extract RGB channel\n",
    "    height, width = img.shape[:2]\n",
    "    img = img.astype(np.float)\n",
    "    img_R, img_G, img_B = img[..., 2].reshape(-1), img[..., 1].reshape(-1), img[..., 0].reshape(-1)\n",
    "\n",
    "    # The entire correction process is carried out in YUV space,\n",
    "    # adjust highlights/shadows in Y space, and adjust colors in UV space\n",
    "    # convert to Y channel (grey intensity) and UV channel (color)\n",
    "    img_Y = .3 * img_R + .59 * img_G + .11 * img_B\n",
    "    img_U = -img_R * .168736 - img_G * .331264 + img_B * .5\n",
    "    img_V = img_R * .5 - img_G * .418688 - img_B * .081312\n",
    "\n",
    "    # extract shadow / highlight\n",
    "    shadow_map = 255 - img_Y * 255 / shadow_tone\n",
    "    shadow_map[np.where(img_Y >= shadow_tone)] = 0\n",
    "    highlight_map = 255 - (255 - img_Y) * 255 / (255 - highlight_tone)\n",
    "    highlight_map[np.where(img_Y <= highlight_tone)] = 0\n",
    "\n",
    "    # // Gaussian blur on tone map, for smoother transition\n",
    "    if shadow_amount_percent * shadow_radius > 0:\n",
    "        # shadow_map = cv2.GaussianBlur(shadow_map.reshape(height, width), ksize=(shadow_radius, shadow_radius), sigmaX=0).reshape(-1)\n",
    "        shadow_map = cv2.blur(shadow_map.reshape(height, width), ksize=(shadow_radius, shadow_radius)).reshape(-1)\n",
    "\n",
    "    if highlight_amount_percent * highlight_radius > 0:\n",
    "        # highlight_map = cv2.GaussianBlur(highlight_map.reshape(height, width), ksize=(highlight_radius, highlight_radius), sigmaX=0).reshape(-1)\n",
    "        highlight_map = cv2.blur(highlight_map.reshape(height, width), ksize=(highlight_radius, highlight_radius)).reshape(-1)\n",
    "\n",
    "    # Tone LUT\n",
    "    t = np.arange(256)\n",
    "    LUT_shadow = (1 - np.power(1 - t * (1 / 255), shadow_gain)) * 255\n",
    "    LUT_shadow = np.maximum(0, np.minimum(255, np.int_(LUT_shadow + .5)))\n",
    "    LUT_highlight = np.power(t * (1 / 255), highlight_gain) * 255\n",
    "    LUT_highlight = np.maximum(0, np.minimum(255, np.int_(LUT_highlight + .5)))\n",
    "\n",
    "    # adjust tone\n",
    "    shadow_map = shadow_map * (1 / 255)\n",
    "    highlight_map = highlight_map * (1 / 255)\n",
    "\n",
    "    iH = (1 - shadow_map) * img_Y + shadow_map * LUT_shadow[np.int_(img_Y)]\n",
    "    iH = (1 - highlight_map) * iH + highlight_map * LUT_highlight[np.int_(iH)]\n",
    "    img_Y = iH\n",
    "\n",
    "    # adjust color\n",
    "    if color_percent != 0:\n",
    "        # color LUT\n",
    "        if color_percent > 0:\n",
    "            LUT = (1 - np.sqrt(np.arange(32768)) * (1 / 128)) * color_percent + 1\n",
    "        else:\n",
    "            LUT = np.sqrt(np.arange(32768)) * (1 / 128) * color_percent + 1\n",
    "\n",
    "        # adjust color saturation adaptively according to highlights/shadows\n",
    "        color_gain = LUT[np.int_(img_U ** 2 + img_V ** 2 + .5)]\n",
    "        w = 1 - np.minimum(2 - (shadow_map + highlight_map), 1)\n",
    "        img_U = w * img_U + (1 - w) * img_U * color_gain\n",
    "        img_V = w * img_V + (1 - w) * img_V * color_gain\n",
    "\n",
    "    # re convert to RGB channel\n",
    "    output_R = np.int_(img_Y + 1.402 * img_V + .5)\n",
    "    output_G = np.int_(img_Y - .34414 * img_U - .71414 * img_V + .5)\n",
    "    output_B = np.int_(img_Y + 1.772 * img_U + .5)\n",
    "\n",
    "    output = np.row_stack([output_B, output_G, output_R]).T.reshape(height, width, 3)\n",
    "    output = np.minimum(output, 255).astype(np.uint8)\n",
    "    return output\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Rescale array\n",
    "def rescaleFrom0to255(arr):\n",
    "    min_val = arr.min()\n",
    "    max_val = arr.max()\n",
    "\n",
    "    # Rescale the array\n",
    "    arr_rescaled = (arr - min_val) * (255 - 0) / (max_val - min_val) + 0\n",
    "    return arr_rescaled.astype(np.uint8)\n",
    "\n",
    "# Rescale array\n",
    "def rescaleFrom0to1(arr):\n",
    "    min_val = arr.min()\n",
    "    max_val = arr.max()\n",
    "\n",
    "    # Rescale the array\n",
    "    arr_rescaled = (arr - min_val) * (1 - 0) / (max_val - min_val) + 0\n",
    "    return arr_rescaled\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# applu CT window\n",
    "def apply_ct_window(img, window):\n",
    "    # window = (window width, window level)\n",
    "    R = (img-window[1]+0.5*window[0])/window[0]\n",
    "    R[R<0] = 0\n",
    "    R[R>1] = 1\n",
    "    return R\n",
    "\n",
    "# enlarge image layout\n",
    "def enlargeImageLayout(input,outputSize):\n",
    "    size = input.shape\n",
    "    output = np.zeros((outputSize))\n",
    "    startX = outputSize[0]//2 - size[0]//2\n",
    "    startY = outputSize[1]//2 - size[1]//2\n",
    "    output[startX:startX+size[0],startY:startY+size[1]] = input\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9ee4c90",
   "metadata": {},
   "source": [
    "## Dicom Categorizing："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06277e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照series對MRI與PET做資料夾分類，並使用json檔案生成MRI對應的label圖像\n",
    "for i in range(10,23):\n",
    "    patientNo = str(i).zfill(3)\n",
    "    mri_dict = getCategorizedDictByFolder('./20230628/PT_MR/'+ patientNo+ '/MR/')\n",
    "    pet_dict = getCategorizedDictByFolder('./20230628/PT_MR/'+ patientNo+ '/PT/')\n",
    "\n",
    "    for patient in mri_dict:\n",
    "        for study in mri_dict[patient]:\n",
    "            for series in mri_dict[patient][study]:\n",
    "                seriesDescripiton = dcmread(mri_dict[patient][study][series][0]['dcmPath']).SeriesDescription\n",
    "                seriesDescripiton = seriesDescripiton.replace('/',' ')\n",
    "                seriesDescripiton = seriesDescripiton.replace('*','')\n",
    "                path = 'categorized/20230628/'+ patientNo+ '/MRI/'+ series + ' (' + seriesDescripiton + ')'\n",
    "                labelPath = 'categorized/20230628/'+ patientNo+ '/MRI/'+ series + ' (' + seriesDescripiton + ')' + '/label/'\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                if not os.path.exists(labelPath):\n",
    "                    os.makedirs(labelPath)\n",
    "                for c,v in enumerate(mri_dict[patient][study][series]):\n",
    "                    shutil.copy(v['dcmPath'],path+ '/'+ str(c+1).zfill(3)+ '.dcm')\n",
    "                    width = dcmread(v['dcmPath']).pixel_array.shape[0]\n",
    "                    height = dcmread(v['dcmPath']).pixel_array.shape[1]\n",
    "                    labelImg = Image.new('RGBA', (width, height))\n",
    "                    if(v['labelPath']!='NA'):                    \n",
    "                        labelImg = getLabeledImageWithJson(v['labelPath'])\n",
    "                    labelImg.save(labelPath + str(c+1).zfill(3) + '.png')\n",
    "                    \n",
    "    for patient in pet_dict:\n",
    "        for study in pet_dict[patient]:\n",
    "            for series in pet_dict[patient][study]:\n",
    "                seriesDescripiton = dcmread(pet_dict[patient][study][series][0]['dcmPath']).SeriesDescription\n",
    "                seriesDescripiton = seriesDescripiton.replace('/',' ')\n",
    "                path = 'categorized/20230628/'+ patientNo+ '/PET/'+ series + ' (' + seriesDescripiton + ')'\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                for c,v in enumerate(pet_dict[patient][study][series]):\n",
    "                    shutil.copy(v['dcmPath'],path+ '/'+ str(c+1).zfill(3)+ '.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0c0a07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複製每個病人的MRI、CT、PETCT到corresponded資料夾（準備對應工作）\n",
    "\n",
    "def find_with_substring(arr, substring):\n",
    "    for string in arr:\n",
    "        if substring in string:\n",
    "            return string\n",
    "    return None\n",
    "\n",
    "mriWithLabelList = [ 'dark-fluid','FLAIR','dark-fluid','FLAIR','FLAIR',\n",
    "                    'dark-fluid','dark-fluid','dark-fluid','dark-fluid','t1_fl2d_tra',\n",
    "                    'TRA_T1W_3D','FLAIR','T1W_tra','t1_fl2d_tra_fs','FLAIR',\n",
    "                    'FLAIR','FLAIR','dark-fluid','FLAIR','dark-fluid',\n",
    "                    'FLAIR','dark-fluid','dark-fluid','t1_fl2d_tra','dark-fluid',\n",
    "                    't1_fl2d_tra_fs','t1_fl2d_tra_fs','t1_fl2d_tra_fs','T1W_TRA' ]\n",
    "\n",
    "for i in range(1,30):\n",
    "    patientNo = str(i).zfill(3)\n",
    "\n",
    "    mriDir = './categorized/20230209/'+patientNo+'/MRI/'\n",
    "    mriDir = mriDir+find_with_substring(os.listdir(mriDir), mriWithLabelList[i-1])\n",
    "    mris = glob.glob(mriDir+'/*.dcm')\n",
    "    labels = glob.glob(mriDir+'/label/'+'*.png')\n",
    "\n",
    "    ctDir = './categorized/20230209/'+patientNo+'/PET/'\n",
    "    ctDir = ctDir+find_with_substring(os.listdir(ctDir),'WB ')\n",
    "    cts = glob.glob(ctDir+'/*.dcm')\n",
    "\n",
    "    petctDir = './categorized/20230209/'+patientNo+'/PET/'\n",
    "    petctDir = petctDir+find_with_substring(os.listdir(petctDir),'Axial')\n",
    "    petcts = glob.glob(petctDir+'/*.dcm')\n",
    "\n",
    "    for j in range(len(mris)):        \n",
    "        dstMriDir = './corresponded/20230209/'+patientNo+'/MRI/'\n",
    "        dstLabelDir = './corresponded/20230209/'+patientNo+'/label/'\n",
    "\n",
    "        if not os.path.exists(dstMriDir):\n",
    "            os.makedirs(dstMriDir)\n",
    "        if not os.path.exists(dstLabelDir):\n",
    "            os.makedirs(dstLabelDir)        \n",
    "        \n",
    "        shutil.copy(mris[j],dstMriDir)\n",
    "        shutil.copy(labels[j],dstLabelDir)\n",
    "\n",
    "    for j in range(70):\n",
    "        dstCtDir = './corresponded/20230209/'+patientNo+'/CT/'\n",
    "        dstPetctDir = './corresponded/20230209/'+patientNo+'/PETCT/'\n",
    "\n",
    "        if not os.path.exists(dstCtDir):\n",
    "            os.makedirs(dstCtDir)\n",
    "        if not os.path.exists(dstPetctDir):\n",
    "            os.makedirs(dstPetctDir)\n",
    "            \n",
    "        shutil.copy(cts[j],dstCtDir)\n",
    "        shutil.copy(petcts[j],dstPetctDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "32720a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicom格式轉換成png\n",
    "import dicom2jpg\n",
    "for i in range(5,6):\n",
    "    mriDicomFolder = './corresponded/20230209/'+str(i).zfill(3)+'/MRI/'\n",
    "    dicom2jpg.dicom2png(mriDicomFolder, target_root=mriDicomFolder)\n",
    "    mriDicomFolder = './corresponded/20230209/'+str(i).zfill(3)+'/CT/'\n",
    "    dicom2jpg.dicom2png(mriDicomFolder, target_root=mriDicomFolder)\n",
    "    mriDicomFolder = './corresponded/20230209/'+str(i).zfill(3)+'/PETCT/'\n",
    "    dicom2jpg.dicom2png(mriDicomFolder, target_root=mriDicomFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54cb4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移動轉換png后的圖片到跟dicom同一個目錄的png目錄下，並重新按照順序命名\n",
    "\n",
    "#找不是.dcm的文件夾名稱\n",
    "def find_folder_name(arr, substring):\n",
    "    for string in arr:\n",
    "        if substring not in string:\n",
    "            return string\n",
    "    return None\n",
    "\n",
    "def doit(mode):\n",
    "    for i in range(2,30):\n",
    "        patientNo = str(i).zfill(3)\n",
    "        rootDir = './corresponded/20230209/'+patientNo+'/'+mode+'/'\n",
    "        rootDir = rootDir + find_folder_name(os.listdir(rootDir),'.dcm') + '/'\n",
    "        toDeleteFolder = rootDir\n",
    "        rootDir = rootDir + os.listdir(rootDir)[0] + '/'\n",
    "        rootDir = rootDir + os.listdir(rootDir)[0] + '/'\n",
    "        pngs = glob.glob(rootDir+'*.png')\n",
    "        pngs.sort(key=lambda x: len(x), reverse=False)\n",
    "        renameFolder = './corresponded/20230209/'+patientNo+'/'+mode+'/png/'\n",
    "        if not os.path.exists(renameFolder):\n",
    "            os.makedirs(renameFolder)\n",
    "        for c,v in enumerate(pngs):\n",
    "            os.rename(v, renameFolder + str(c+1).zfill(3) + '.png')\n",
    "        shutil.rmtree(toDeleteFolder)\n",
    "\n",
    "doit('CT')\n",
    "doit('MRI')\n",
    "doit('PETCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "120247a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files (因轉換後檔案名稱在排序上有問題，需要重新命名)\n",
    "for i in range(29):\n",
    "    startNum = 1\n",
    "    renameFolder = './corresponded/20230209/'+str(i+1).zfill(3)+'/CT/'\n",
    "    files = glob.glob(renameFolder + \"*.png\")\n",
    "    files.sort(key=lambda x: len(x), reverse=False)\n",
    "    for c,v in enumerate(files):\n",
    "        os.rename(v, renameFolder + str(c+startNum).zfill(3) + '.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4c61d77",
   "metadata": {},
   "source": [
    "## Preprocessing of Image Registration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f3bde2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientNo = '029'\n",
    "mriPath = './corresponded/20230209/'+patientNo+'/MRI/'\n",
    "ctPath = './corresponded/20230209/'+patientNo+'/CT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7143e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "MRI: [0.44921875, 0.44921875]\n",
      "(512, 512)\n",
      "CT: [1.367188, 1.367188]\n",
      "Ratio: 1.8910939799071338\n"
     ]
    }
   ],
   "source": [
    "# 計算MRI與PET之間的voxel物理大小 與 兩者之間的縮放比例\n",
    "mri = dcmread(mriPath + '001.dcm')\n",
    "ct = dcmread(ctPath + '001.dcm')\n",
    "petctPixelRatio = ct.pixel_array.shape[0]/824\n",
    "mriPixelSpacing = mri.PixelSpacing\n",
    "ctPixelSpacing = ct.PixelSpacing\n",
    "# pixelRatio = ct.pixel_array.shape[0]/mri.pixel_array.shape[0]\n",
    "physicalRatio = ctPixelSpacing[0]/mriPixelSpacing[0]\n",
    "rescaleRatio = physicalRatio * petctPixelRatio # petctPixelRatio（ct與petct的解析度比例，調整一樣的解析度后内容大小一樣） / scalar->ex:0.87（ct與petct的内容大小比例）\n",
    "print(mri.pixel_array.shape)\n",
    "print('MRI: ' + str(mriPixelSpacing))\n",
    "print(ct.pixel_array.shape)\n",
    "print('CT: ' + str(ctPixelSpacing))\n",
    "print('Ratio: ' + str(rescaleRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e1f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對圖片矩陣進行翻轉/旋轉至原本的狀態（3D slicer輸出的nii會導致圖片翻轉）,並調整成240*240*48\n",
    "dir = glob.glob('./petct_training_dataset/*.nii.gz')\n",
    "for ds in dir:\n",
    "    petct_nii = nib.load(ds).get_fdata()\n",
    "    result = np.zeros((240,240,48))\n",
    "    for i in range(48):\n",
    "        if(i<petct_nii.shape[2]):\n",
    "            result[:,:,i] = cv2.resize(np.fliplr(np.rot90(petct_nii[:,:,i],3)),(240,240))\n",
    "    nib.save(nib.Nifti1Image(result, affine=np.eye(4)), ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2121bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot comparison between MRI and registered PETCT\n",
    "patientNo = '003'\n",
    "mris = nib.load('./mri_training_dataset/size_fixed/0_'+patientNo+'.nii.gz').get_fdata()\n",
    "labels = nib.load('./petct_training_dataset/size_fixed/0_'+patientNo+'_seg.nii.gz').get_fdata()\n",
    "petcts = nib.load('./petct_training_dataset/size_fixed/0_'+patientNo+'.nii.gz').get_fdata()\n",
    "cols = 3\n",
    "rows = 48\n",
    "fig = plt.figure(figsize=(6, 100))\n",
    "for n_slice in range(rows):\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+1)\n",
    "    ax.set_title('mri')\n",
    "    plt.imshow(mris[:,:,n_slice],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+2)\n",
    "    ax.set_title('petct')\n",
    "    plt.imshow(petcts[:,:,n_slice],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+3)\n",
    "    ax.set_title('label')\n",
    "    plt.imshow(labels[:,:,n_slice])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d38781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#superimpose label to mri and petct then save image\n",
    "patientNo = '015'\n",
    "correspondedMRIPaths = glob.glob('corresponded/20230209/'+patientNo+'/MRI/png/*.png')\n",
    "correspondedLabelPaths = glob.glob('corresponded/20230209/'+patientNo+'/label/contour/*.png')\n",
    "petcts = nib.load('./petct_training_dataset/20230209/'+patientNo+'.nii.gz').get_fdata()\n",
    "cols = 2\n",
    "rows = petcts.shape[2]\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "for n_slice in range(rows):\n",
    "    mri = Image.open(correspondedMRIPaths[n_slice])\n",
    "    label = Image.open(correspondedLabelPaths[n_slice])\n",
    "    petct = Image.fromarray(petcts[:,:,n_slice])\n",
    "    mri.paste(label,(0,0),mask=label)\n",
    "    petct.paste(label,(0,0),mask=label)\n",
    "    ax=fig.add_subplot(1,cols,1)\n",
    "    ax.set_title(\"MRI\",fontsize=22)\n",
    "    plt.imshow(mri,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(1,cols,2)\n",
    "    ax.set_title(\"PETCT\",fontsize=22)\n",
    "    plt.imshow(np.array(petct),cmap='hot')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(str(n_slice+1).zfill(3) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare 1-channel mri(flair or dark_fluid) for training:\n",
    "for i in range(1,30):\n",
    "    patientNo = str(i).zfill(3)\n",
    "    mriDir = glob.glob('corresponded/20230209/'+patientNo+'/mri/png/*.png')\n",
    "    size = io.imread(mriDir[0]).shape[0]\n",
    "    result = np.zeros((size,size,len(mriDir)))\n",
    "    for i in range(len(mriDir)):\n",
    "        mri = io.imread(mriDir[i])\n",
    "        result[:,:,i] = mri\n",
    "    nib.save(nib.Nifti1Image(result, affine=np.eye(4)), './mri_training_dataset/1_'+patientNo+'_mri.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa88d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare label for training:\n",
    "for i in range(14,15):\n",
    "    patientNo = str(i).zfill(3)\n",
    "    labelDir = glob.glob('corresponded/20230209/'+patientNo+'/label/*.png')\n",
    "    label_res = np.zeros((240,240,48))\n",
    "    for i in range(len(labelDir)):\n",
    "        if(i<48):\n",
    "            label_res[:,:,i] = cv2.resize(io.imread(labelDir[i]),(240,240))\n",
    "    nib.save(nib.Nifti1Image(label_res, affine=np.eye(4)), './petct_training_dataset/1_'+patientNo+'_seg.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f7f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change petct and label to the same size (240*240*48)\n",
    "petctDir = glob.glob('./petct_training_dataset/*.nii.gz')\n",
    "size = 240\n",
    "depth = 48\n",
    "for i in petctDir:    \n",
    "    result = np.zeros((size,size,depth))\n",
    "    nii = nib.load(i).get_fdata()\n",
    "    for j in range(depth):\n",
    "        if(j<nii.shape[2]):\n",
    "            result[:,:,j] = resize(nii[:,:,j],(size,size),anti_aliasing=False)\n",
    "    nib.save(nib.Nifti1Image(result, affine=np.eye(4)), './petct_training_dataset/size_fixed_128/'+i.split('\\\\')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7198c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale nii label value from range of 0 to 1\n",
    "petctDir = glob.glob('./petct_training_dataset/*seg.nii.gz')\n",
    "for i in petctDir:\n",
    "    nii = nib.load(i).get_fdata()\n",
    "    nii[nii<127] = 0\n",
    "    nii[nii>=127] = 1\n",
    "    nib.save(nib.Nifti1Image(nii, affine=np.eye(4)), i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9cb3aed",
   "metadata": {},
   "source": [
    "## Image Fusing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 64)\n",
      "(512, 512, 64)\n"
     ]
    }
   ],
   "source": [
    "# Image Fusing for PET and CT\n",
    "patient_id = str(400).zfill(3)\n",
    "saveDir = './petct_training_dataset/fused/'\n",
    "ct = nib.load(f'./petct_training_dataset/registrated/{patient_id}_ct.nii.gz').get_fdata()\n",
    "pet = nib.load(f'./petct_training_dataset/registrated/{patient_id}_pet.nii.gz').get_fdata()\n",
    "res = np.zeros((256,256,ct.shape[2]))\n",
    "print(ct.shape)\n",
    "print(pet.shape)\n",
    "xs = 115\n",
    "ys = 80\n",
    "for i in range(ct.shape[2]):\n",
    "    alpha = 0.5\n",
    "    beta = 1 - alpha\n",
    "    fused = cv2.addWeighted(apply_ct_window(ct[:,:,i],(300,40)),alpha,rescaleFrom0to1(pet[:,:,i]),beta,0.0)\n",
    "    res[:,:,i] = fused[xs:xs+256,ys:ys+256]\n",
    "nib.save(nib.Nifti1Image(res, affine=np.eye(4)), saveDir + f'{patient_id}_petct.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2def0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save petct and label to nii for training\n",
    "from skimage.transform import resize\n",
    "patientNum = '015'\n",
    "petcts = glob.glob('../dataset/PETCT/NoTumorInBrian/'+patientNum+'/petct/*.png')\n",
    "# labels = glob.glob('../dataset/PETCT/NoTumorInBrian/'+patientNum+'/label/*.png')\n",
    "imgSize = 128\n",
    "slicesNum = 48\n",
    "petct = np.zeros((imgSize,imgSize,slicesNum))\n",
    "seg = np.zeros((imgSize,imgSize,slicesNum))\n",
    "for i in range(slicesNum):\n",
    "    if(i>=len(petcts)):\n",
    "        petct[:,:,i] = np.zeros((imgSize,imgSize))\n",
    "        seg[:,:,i] = np.zeros((imgSize,imgSize))\n",
    "    else:\n",
    "        img = io.imread(petcts[i])\n",
    "        # label = io.imread(labels[i])[:,:]\n",
    "        # print(np.unique(label))\n",
    "        # if(img.shape[0]>imgSize):\n",
    "        #     img = rescaleFrom0to255(resize(img,(imgSize,imgSize)))\n",
    "        # if(label.shape[0]>imgSize):\n",
    "        #     label = rescaleFrom0to255(resize(label,(imgSize,imgSize)))\n",
    "        petct[:,:,i] = img\n",
    "        # seg[:,:,i] = label\n",
    "seg[seg!=0] = 1\n",
    "nib.save(nib.Nifti1Image(petct, affine=np.eye(4)), 'pet_training_dataset/FDG/' + patientNum + '_pet.nii.gz')\n",
    "nib.save(nib.Nifti1Image(seg, affine=np.eye(4)), 'pet_training_dataset/FDG/' + patientNum + '_pet_seg.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fee0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate saved pet nib (compare with original mri)\n",
    "patientNum = '003'\n",
    "mri = glob.glob('./corresponded/'+patientNum+'/shaped/*.png')\n",
    "pet = nib.load('../U-net/pet_training_dataset/'+patientNum+'_pet.nii.gz').get_fdata()\n",
    "seg = nib.load('../U-net/pet_training_dataset/'+patientNum+'_pet_seg.nii.gz').get_fdata()\n",
    "print(pet.shape)\n",
    "print(seg.shape)\n",
    "print(np.unique(seg))\n",
    "cols = 3\n",
    "rows = 48\n",
    "fig = plt.figure(figsize=(6,100))\n",
    "for n_slice in range(rows):\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+1)\n",
    "    plt.imshow(pet[:,:,n_slice],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+2)\n",
    "    plt.imshow(pet[:,:,n_slice],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax=fig.add_subplot(rows,cols,(n_slice*cols)+3)\n",
    "    plt.imshow(seg[:,:,n_slice])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe857db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save petct dicom to gray image\n",
    "dir = './categorized/20221005/001/PET/1353 (FDG WBS PET CT Axial)/'\n",
    "petct = glob.glob(dir+'*.dcm')\n",
    "save_dir = dir+'png/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "for i in range(70):\n",
    "    img = dcmread(petct[i]).pixel_array\n",
    "    img = color.rgb2gray(ds)\n",
    "    io.imsave(save_dir+str(i+1).zfill(3)+'.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fce5960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 對MRI進行LUT對比度增强后再進行保存成nifti格式\n",
    "dir = glob.glob('./corresponded/20230209/029/MRI/*.dcm')\n",
    "result = np.zeros((240,240,48))\n",
    "for i in range(48):\n",
    "    if(i<len(dir)):\n",
    "        ds = dcmread(dir[i])\n",
    "        img = pixel_process(ds,ds.pixel_array)\n",
    "        result[:,:,i] = cv2.resize(img,(240,240))\n",
    "nib.save(nib.Nifti1Image(result, affine=np.eye(4)), '1_029_mri.nii.gz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07b02c22",
   "metadata": {},
   "source": [
    "## Preparing nifti for training from TCIA_MRI_Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare 256x256x64 nii file\n",
    "root_dir = '../TCIA_MRI_Dataset/'\n",
    "folders = glob.glob(os.path.join(root_dir,'TCGA*'))\n",
    "save_dir = './mri_training_dataset/TCIA/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "for c,folder in enumerate(folders):\n",
    "    tifs = glob.glob(os.path.join(folder,'*.tif'))\n",
    "    mris = []\n",
    "    for i in tifs:\n",
    "        if 'mask' not in i:\n",
    "            mris.append(i)\n",
    "    mris = sorted(mris, key=lambda x:len(x))[::-1]\n",
    "    labels = glob.glob(os.path.join(folder,'*mask.tif'))\n",
    "    labels = sorted(labels, key=lambda x:len(x))[::-1]\n",
    "    mri_res = np.zeros((256,256,64))\n",
    "    label_res = np.zeros((256,256,64))\n",
    "    n = 0\n",
    "    for i in range(64):\n",
    "        if(i<len(mris)):\n",
    "            mri_res[:,:,i] = io.imread(mris[i])[:,:,1]\n",
    "            label_res[:,:,i] = io.imread(labels[i])\n",
    "    label_res[label_res==255] = 1\n",
    "    nib.save(nib.Nifti1Image(mri_res, affine=np.eye(4)), save_dir + folder.split('\\\\')[-1] + '.nii.gz')\n",
    "    nib.save(nib.Nifti1Image(label_res, affine=np.eye(4)), save_dir + folder.split('\\\\')[-1] + '_mask.nii.gz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0d126a0",
   "metadata": {},
   "source": [
    "## Preparing nifti for normal_mri:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = '022'\n",
    "flair_tag = '501 (C+T2_FLAIR_FS)'\n",
    "flair_dir = glob.glob(f'./categorized/20230628/{patient_id}/MRI/{flair_tag}/*.dcm')\n",
    "flair_dir.sort(key=lambda x: len(x))\n",
    "save_dir = './mri_training_dataset/normal_flair/'\n",
    "width = dcmread(flair_dir[0]).pixel_array.shape[0]\n",
    "height = dcmread(flair_dir[0]).pixel_array.shape[1]\n",
    "depth = len(flair_dir)\n",
    "mri_res = np.zeros((width,height,depth))\n",
    "label_res = np.zeros((width,height,depth))\n",
    "for c,v in enumerate(flair_dir):\n",
    "    ds = dcmread(v).pixel_array\n",
    "    mri_res[:,:,c] = ds\n",
    "nib.save(nib.Nifti1Image(mri_res, affine=np.eye(4)), save_dir +  patient_id + '_mri.nii.gz')\n",
    "nib.save(nib.Nifti1Image(label_res, affine=np.eye(4)), save_dir + patient_id + '_mask.nii.gz')\n",
    "io.imshow(mri_res[:,:,10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
